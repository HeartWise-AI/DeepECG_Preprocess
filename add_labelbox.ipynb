{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "def df_stats(df):\n",
    "    from tabulate import tabulate\n",
    "    print(\"\\n***** Shape: \", df.shape,\" *****\\n\")\n",
    "    \n",
    "    columns_list = df.columns.values.tolist()\n",
    "    isnull_list = df.isnull().sum().values.tolist()\n",
    "    isunique_list = df.nunique().values.tolist()\n",
    "    dtypes_list = df.dtypes.tolist()\n",
    "    \n",
    "    list_stat_val = list(zip(columns_list, isnull_list, isunique_list, dtypes_list))\n",
    "    df_stat_val = pd.DataFrame(list_stat_val, columns=['Name', 'Null', 'Unique', 'Dtypes'])\n",
    "    print(tabulate(df_stat_val, headers='keys', tablefmt='psql'))\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the labelbox annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import labelbox\n",
    "# Enter your Labelbox API key here\n",
    "LB_API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJjbDh2eGdsaHAweTlzMDh6ZmdyOXM3Z28zIiwib3JnYW5pemF0aW9uSWQiOiJjbDh2eGdsaDgweTlyMDh6ZjNybzNkbXg2IiwiYXBpS2V5SWQiOiJjbGV2aTA4ejEwMzBmMDczZjIzb2UxZnExIiwic2VjcmV0IjoiNTExMDIwNzcxODk3MmRjM2MyMTI0MDRjNTI5ZGFjY2UiLCJpYXQiOjE2NzgwMjcwOTQsImV4cCI6MjMwOTE3OTA5NH0.kTAKOI5Sm7wE3IeEjZTGpwc1u4aU0Ya5mzt4eOHa-wQ\"\n",
    "client = labelbox.Client(api_key=LB_API_KEY)\n",
    "PROJECT_ID = 'cl8vxju2k0z0q07ztfyt5dr7l'\n",
    "project = client.get_project(PROJECT_ID)\n",
    "labels = project.export_v2(params={\n",
    "\t\"data_row_details\": False,\n",
    "\t\"metadata_fields\": False,\n",
    "\t\"attachments\": False,\n",
    "\t\"project_details\": False,\n",
    "\t\"performance_details\": False,\n",
    "\t\"label_details\": False,\n",
    "\t\"interpolated_frames\": False\n",
    "  })\n",
    "labels.wait_till_done()\n",
    "\n",
    "if labels.errors:\n",
    "  print(labels.errors)\n",
    "\n",
    "export_json = labels.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the labelbox hot-encoding for the Labelbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_labels(label_dict):\n",
    "    \"\"\"\n",
    "    Flattens the labels from a Labelbox sub-dictionary into a predictable structure.\n",
    "\n",
    "    Parameters:\n",
    "        label_dict (dict): A Labelbox sub-dictionary object.\n",
    "\n",
    "    Returns:\n",
    "        dict: Flattened dictionary with key categories and their corresponding features.\n",
    "    \"\"\"\n",
    "    flattened_dict = {\n",
    "        'Rhythm': [], 'QRS complex': [], 'Wave criterias': [], \n",
    "        'Conduction': [], 'Chamber enlargement': [], 'Other': [],\n",
    "        'ST segments': [], 'P-wave morphology': []\n",
    "    }\n",
    "    classification_dict = label_dict['classifications']\n",
    "\n",
    "    for category in classification_dict:\n",
    "        category_name = category['name']\n",
    "        for feature in category['checklist_answers']:\n",
    "            flattened_dict[category_name].append(feature['name'])\n",
    "\n",
    "    return flattened_dict\n",
    "\n",
    "\n",
    "def adjust_name(label_dict):\n",
    "    \"\"\"\n",
    "    Modifies the dictionary to use the original patient ID as the key.\n",
    "    \n",
    "    Parameters:\n",
    "        label_dict (dict): Dictionary with Labelbox original ECG ID as key.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with Patient ID as the new key.\n",
    "    \"\"\"\n",
    "    modified_dict = {}\n",
    "    for key, value in label_dict.items():\n",
    "        modified_key = key.split('_')[1] + '_' + key.split('_')[2] + '_' + key.split('_')[3]\n",
    "        modified_dict[modified_key] = value\n",
    "\n",
    "    return modified_dict\n",
    "\n",
    "\n",
    "def get_single_value(label_dict):\n",
    "    \"\"\"\n",
    "    Filters the dictionary to include only non-empty label categories.\n",
    "    \n",
    "    Parameters:\n",
    "        label_dict (dict): Dictionary with both empty and filled Labelbox label categories.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary with only positive labels, without category information.\n",
    "    \"\"\"\n",
    "\n",
    "    filtered_dict = {}\n",
    "\n",
    "    for key, value in label_dict.items():\n",
    "        for subkey, subvalue in value['annotations'].items():\n",
    "            if key not in filtered_dict:\n",
    "                filtered_dict[key] = subvalue\n",
    "            else:\n",
    "                filtered_dict[key].extend(subvalue)\n",
    "\n",
    "    return filtered_dict\n",
    "\n",
    "\n",
    "def get_hot_labels(dict_, df):\n",
    "    \"\"\"\n",
    "    Generates a one_hot encoded vector for a dictionary containing its unique positive labels.\n",
    "    For multiple examples per 'Diagnosis', it takes the max value for the keys (1) between the examples.\n",
    "\n",
    "    Parameters:\n",
    "        dict_: a dictionary with only positive labels, no category.\n",
    "        df: DataFrame to match keys with 'Diagnosis'.\n",
    "    Returns:\n",
    "        dict: a dictionary with 'Diagnosis' as keys and one-hot encoded vectors as values.\n",
    "        list: list of the features used, used to generate the df columns.\n",
    "    \"\"\"\n",
    "\n",
    "    list_features = list()\n",
    "    # Create a list of unique features\n",
    "    for v in dict_.values():\n",
    "        for i in v:\n",
    "            if i not in list_features:\n",
    "                list_features.append(i)\n",
    "\n",
    "    out_dict = dict()\n",
    "    # Loop through each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # Construct the key as in dict_\n",
    "        key = f\"{row['RestingECG_PatientDemographics_PatientID']}_{row['RestingECG_TestDemographics_AcquisitionDate']}_{row['RestingECG_TestDemographics_AcquisitionTime']}\"\n",
    "        # Check if this key is in dict_\n",
    "        if key in dict_:\n",
    "            out_list = [0] * len(list_features)\n",
    "            for i in dict_[key]:\n",
    "                for pos, feature in enumerate(list_features):\n",
    "                    if feature == i:\n",
    "                        out_list[pos] = 1\n",
    "            # Use 'Diagnosis' as the key in out_dict\n",
    "            diagnosis = row['Diagnosis']\n",
    "            if diagnosis in out_dict:\n",
    "                # Merge by taking max value for each feature\n",
    "                out_dict[diagnosis] = [max(a, b) for a, b in zip(out_dict[diagnosis], out_list)]\n",
    "            else:\n",
    "                out_dict[diagnosis] = out_list\n",
    "\n",
    "    return out_dict, list_features\n",
    "\n",
    "# Example usage\n",
    "# out_dict, list_features = get_hot_labels(positive_labels_dict, labelbox_df_prelabelling)\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def generate_cleaned_dict_v2_no_tqdm(label_box_data, labelbox_df_prelabelling):\n",
    "    \"\"\"\n",
    "    Processes Labelbox data to extract and flatten labels, and generates one-hot encoded vectors.\n",
    "    Modified to work without tqdm for progress visualization.\n",
    "\n",
    "    Parameters:\n",
    "        label_box_data (list): List of Labelbox data entries.\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing dictionaries of flattened labels, positive labels, and one-hot encoded vectors,\n",
    "        along with a list of feature names and a DataFrame.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    flattened_dict = {}\n",
    "    positive_labels_dict = {}\n",
    "    i = 0\n",
    "\n",
    "    for annotation in tqdm(label_box_data):\n",
    "  \n",
    "        name = annotation['data_row']['external_id'].split('.')[0]\n",
    "        project_labels = annotation['projects']['cl8vxju2k0z0q07ztfyt5dr7l']['labels'][0]\n",
    "        annotations = project_labels.get('annotations', {})\n",
    "        \n",
    "        if annotations:\n",
    "            flattened_labels = flatten_labels(annotations)\n",
    "            positive_labels = adjust_name(get_single_value({name: {'annotations': flattened_labels}}))\n",
    "            positive_labels_dict.update(positive_labels)\n",
    "            flattened_dict[name] = project_labels\n",
    "\n",
    "\n",
    "    one_hot_encoded, feature_list = get_hot_labels(positive_labels_dict, labelbox_df_prelabelling)\n",
    "    print(one_hot_encoded)\n",
    "    print(feature_list)\n",
    "    df_one_hot = pd.DataFrame.from_dict(one_hot_encoded, orient='index', columns=feature_list)\n",
    "\n",
    "    return flattened_dict, positive_labels_dict, one_hot_encoded, feature_list, df_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelbox_df_prelabelling = pd.read_csv(\"/media/data1/anolin/20221002_ECG_mod_diagnosis_sampled_3600.csv\")\n",
    "labelbox_df_prelabelling['RestingECG_PatientDemographics_PatientID'] = [str(n).zfill(7) for n in labelbox_df_prelabelling['patientid'].tolist()]\n",
    "#Drop patientid\n",
    "labelbox_df_prelabelling.drop(columns=['patientid'], inplace=True)\n",
    "## Rename labelbox_df_prelabelling['AcquisitionDate'] to labelbox_df_prelabelling['RestingECG_TestDemographics_AcquisitionDate']\n",
    "labelbox_df_prelabelling.rename(columns={'AcquisitionDate':'RestingECG_TestDemographics_AcquisitionDate'}, inplace=True)\n",
    "## Rename AcquisitioNTime to RestingECG_TestDemographics_AcquisitionTime\n",
    "labelbox_df_prelabelling.rename(columns={'AcquisitionTime':'RestingECG_TestDemographics_AcquisitionTime'}, inplace=True)\n",
    "\n",
    "# this basically fills a dict where the key is a unique diag and the values\n",
    "# is a list that is filled with each patient ID with an exact match for that diag\n",
    "dict_diag = dict()\n",
    "#ROBERT : 2023-11-22 CHANGED TO DIAGNOSIS\n",
    "for k,v in zip(labelbox_df_prelabelling['Diagnosis'].tolist(),labelbox_df_prelabelling['RestingECG_PatientDemographics_PatientID'].tolist()):\n",
    "    if k in dict_diag:\n",
    "        dict_diag[k].append(v)\n",
    "\n",
    "    else:\n",
    "        dict_diag.update({k:[v]})\n",
    "\n",
    "display(labelbox_df_prelabelling.loc[labelbox_df_prelabelling['RestingECG_PatientDemographics_PatientID'] == '0590682'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the final one-hot-encoded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_flatten, dict_labels, one_hot_encoded, feature_list, final_one_hot = generate_cleaned_dict_v2_no_tqdm(export_json, labelbox_df_prelabelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column 'all_values' with array of all values in each row\n",
    "final_one_hot['all_values'] = final_one_hot.apply(lambda row: row.values, axis=1)\n",
    "# Identifying rows where all values are 0\n",
    "# Excluding the 'all_values' and 'Unnamed: 0' columns for this check\n",
    "zero_value_rows = final_one_hot[final_one_hot.drop(columns=['all_values']).eq(0).all(axis=1)].reset_index()\n",
    "\n",
    "# Displaying the rows with all zero values\n",
    "display(zero_value_rows.describe())\n",
    "display(zero_value_rows['index'])\n",
    "## ROBERT : This should be \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find the patients equivalent to those annotated\n",
    "# annotation with exact string matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dir_ = '/media/data1/anolin/temp_new_dataset/df_xml_2023_11_25_FINAL_CONCAT.parquet'\n",
    "df_ecg = pd.read_parquet(dir_, engine='fastparquet')\n",
    "\n",
    "#make sure patient len(id) == 7\n",
    "df_ecg['RestingECG_PatientDemographics_PatientID'] = [n.zfill(7) for n in df_ecg['RestingECG_PatientDemographics_PatientID'].tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(df_ecg.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure the date column is in datetime format\n",
    "df_ecg['RestingECG_TestDemographics_AcquisitionDate'] = pd.to_datetime(df_ecg['RestingECG_TestDemographics_AcquisitionDate'])\n",
    "\n",
    "# Extract year and month\n",
    "df_ecg['Year'] = df_ecg['RestingECG_TestDemographics_AcquisitionDate'].dt.year\n",
    "df_ecg['Month'] = df_ecg['RestingECG_TestDemographics_AcquisitionDate'].dt.month\n",
    "df_ecg = df_ecg.groupby(['npy_path']).first().reset_index()\n",
    "# Group by year and month and count the ECGs\n",
    "ecg_counts = df_ecg.groupby(['Year', 'Month']).size().reset_index(name='ECG_Counts')\n",
    "# Display the results by months\n",
    "print(ecg_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.height', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('max_colwidth', 200)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "display(df_ecg.loc[(df_ecg['RestingECG_PatientDemographics_PatientID'] == '0067241') & (df_ecg['RestingECG_TestDemographics_AcquisitionDate'] == '03-08-2022') & (df_ecg['RestingECG_TestDemographics_AcquisitionTime']=='00:11:07')].diagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_one_hot_vectors(df_ecg, one_hot_encoded, feature_list):\n",
    "    \"\"\"\n",
    "    Appends one_hot_encoded vectors to the rows in df_ecg where 'diagnosis' matches the keys in one_hot_encoded.\n",
    "    Sets the column headers of the appended vectors to the provided feature_list.\n",
    "\n",
    "    Parameters:\n",
    "        df_ecg: DataFrame containing 'diagnosis' column.\n",
    "        one_hot_encoded: Dictionary with diagnosis as keys and one-hot encoded vectors as values.\n",
    "        feature_list: List of feature names corresponding to positions in the one-hot encoded vectors.\n",
    "    Returns:\n",
    "        DataFrame: Modified df_ecg with appended one_hot_encoded vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a list to store the one-hot encoded vectors\n",
    "    one_hot_vectors = []\n",
    "\n",
    "    # Initialize a list to track if a match was found\n",
    "    list_matched = []\n",
    "\n",
    "    # Iterate through each row in df_ecg\n",
    "    for index, row in tqdm(df_ecg.iterrows()):\n",
    "        diagnosis = row['diagnosis']\n",
    "        # Check if the diagnosis is in the one_hot_encoded keys\n",
    "        if (diagnosis in one_hot_encoded) & (len(row['diagnosis']) >= 4):\n",
    "            # Append the corresponding one-hot vector\n",
    "            one_hot_vectors.append(one_hot_encoded[diagnosis])\n",
    "            # Indicate a match was found\n",
    "            list_matched.append(1)\n",
    "        else:\n",
    "            # Append a zero vector if no match is found\n",
    "            one_hot_vectors.append([0] * len(feature_list)) # Using the length of feature_list\n",
    "            # Indicate no match was found\n",
    "            list_matched.append(0)\n",
    "\n",
    "    # Convert the list of vectors to a DataFrame and set the column names to feature_list\n",
    "    one_hot_df = pd.DataFrame(one_hot_vectors, columns=feature_list)\n",
    "\n",
    "    # Append the one_hot_df to the original df_ecg\n",
    "    df_ecg_extended = pd.concat([df_ecg, one_hot_df], axis=1)\n",
    "\n",
    "    # Add the 'annotated' column to indicate matches\n",
    "    df_ecg_extended['annotated'] = list_matched\n",
    "\n",
    "    return df_ecg_extended\n",
    "\n",
    "# Example usage\n",
    "# df_ecg_extended = append_one_hot_vectors(df_ecg, one_hot_encoded, feature_list)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "df_ecg_extended = append_one_hot_vectors(df_ecg, one_hot_encoded, feature_list)\n",
    "display(df_ecg_extended.annotated.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dict = {\n",
    "    'Axe gauche': ['Left axis deviation'],\n",
    "    'Axe indéterminé': [],\n",
    "    \"Axe droit\": ['Right axis deviation'],\n",
    "    'Axe nord-ouest': [],\n",
    "    'Axe P anormal': ['Ectopic atrial rhythm (< 100 BPM)'],\n",
    "    'Axe P anormal, rythme auriculaire ectopique possible': ['Ectopic atrial rhythm (< 100 BPM)'],\n",
    "    'onde P intrinsèques': ['Ectopic atrial rhythm (< 100 BPM)'],\n",
    "    'rythme auriculaire ectopique': ['Ectopic atrial rhythm (< 100 BPM)'],\n",
    "    'Rythme sinusal': ['Regular', 'Sinusal']\n",
    "}\n",
    "\n",
    "inverted_dict = {}\n",
    "for key, values in original_dict.items():\n",
    "    for value in values:\n",
    "        if value in inverted_dict:\n",
    "            inverted_dict[value].append(key)\n",
    "        else:\n",
    "            inverted_dict[value] = [key]\n",
    "\n",
    "print(inverted_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do a string cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "\n",
    "def clean_and_format_ecg_string(s):\n",
    "    # Check if the input is a list and join into a single string\n",
    "    if isinstance(s, list):\n",
    "        s = ' '.join(s)\n",
    "\n",
    "    # Remove the specified prefix if it exists in the string\n",
    "    s = s.split(\"*** ATTENTION! mauvaise qualité de l'ECG*** \")[-1]\n",
    "\n",
    "    # Convert the string to lowercase\n",
    "    s = s.lower()\n",
    "\n",
    "    # Remove the specified suffix if it exists in the string\n",
    "    s = s.split(' ecg anormal')[0]\n",
    "\n",
    "    # Convert unicode characters to their closest ASCII representation\n",
    "    s = unidecode(s)\n",
    "\n",
    "    # Remove leading and trailing whitespace\n",
    "    s = s.strip()\n",
    "\n",
    "    # Replace one or more non-word characters (including punctuation) with a single space\n",
    "    s = re.sub(r\"\\W+\", \" \", s)\n",
    "\n",
    "    # Strip whitespace again to ensure removal of space before and after the start of the string\n",
    "    s = s.strip()\n",
    "\n",
    "    return s\n",
    "\n",
    "# Example usage\n",
    "# Assuming df_ecg_extended and one_hot_encoded are already defined\n",
    "df_ecg[\"Clean_and_format_Diag\"] = df_ecg[\"diagnosis\"].apply(clean_and_format_ecg_string)\n",
    "dict_diag = {clean_and_format_ecg_string(k): v for k, v in dict_diag.items()}\n",
    "one_hot_encoded_cleaned = {clean_and_format_ecg_string(k): v for k, v in one_hot_encoded.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_diag = {clean_and_format_ecg_string(k): v for k, v in dict_diag.items()}\n",
    "one_hot_encoded_cleaned = {clean_and_format_ecg_string(k): v for k, v in one_hot_encoded.items()}\n",
    "missing_keys = [key for key in dict_diag.keys() if key not in one_hot_encoded_cleaned.keys()]\n",
    "print(\"Missing keys from labelbox vs dict_diag - should be 0\", len(missing_keys))\n",
    "common_keys = [key for key in dict_diag.keys() if key in one_hot_encoded_cleaned.keys()]\n",
    "print(\"Common keys - should be ALL\", len(common_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_one_hot_vectors_clean_diagnosis(df_ecg_extended_, one_hot_encoded_cleaned, feature_list):\n",
    "    \"\"\"\n",
    "    Appends one_hot_encoded vectors to the rows in df_ecg_extended_ where 'Clean_and_format_diagnosis' matches the keys in one_hot_encoded.\n",
    "    Sets the column headers of the appended vectors to the provided feature_list.\n",
    "\n",
    "    Parameters:\n",
    "        df_ecg_extended_: DataFrame containing 'Clean_and_format_diagnosis' column.\n",
    "        one_hot_encoded: Dictionary with diagnosisnosis as keys and one-hot encoded vectors as values.\n",
    "        feature_list: List of feature names corresponding to positions in the one-hot encoded vectors.\n",
    "    Returns:\n",
    "        DataFrame: Modified df_ecg_extended_ with appended one_hot_encoded vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize a list to store the one-hot encoded vectors\n",
    "    one_hot_vectors = []\n",
    "\n",
    "    # Initialize a list to track if a match was found\n",
    "    list_matched = []\n",
    "\n",
    "    # Iterate through each row in df_ecg_extended_\n",
    "    for index, row in tqdm(df_ecg_extended_.iterrows()):\n",
    "        diagnosis = row['Clean_and_format_Diag']\n",
    "        # Check if the diagnosisnosis is in the one_hot_encoded keys\n",
    "        if diagnosis in one_hot_encoded_cleaned:\n",
    "            # Append the corresponding one-hot vector from one_hot_encoded\n",
    "            one_hot_vectors.append(one_hot_encoded_cleaned[diagnosis])\n",
    "            # Indicate a match was found\n",
    "            list_matched.append(1)\n",
    "        else:\n",
    "            # Append a zero vector if no match is found\n",
    "            one_hot_vectors.append([0] * len(feature_list)) # Using the length of feature_list\n",
    "            # Indicate no match was found\n",
    "            list_matched.append(0)\n",
    "\n",
    "    # Convert the list of vectors to a DataFrame and set the column names to feature_list\n",
    "    one_hot_df = pd.DataFrame(one_hot_vectors, columns=feature_list)\n",
    "\n",
    "    # Append the one_hot_df to the original df_ecg_extended_\n",
    "    df_ecg_extended_extended = pd.concat([df_ecg_extended_, one_hot_df], axis=1)\n",
    "\n",
    "    # Add the 'annotated' column to indicate matches\n",
    "    df_ecg_extended_extended['annotated_method_2'] = list_matched\n",
    "\n",
    "    return df_ecg_extended_extended\n",
    "\n",
    "# Example usage\n",
    "df_ecg_extended_extended = append_one_hot_vectors_clean_diagnosis(df_ecg, one_hot_encoded_cleaned, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_ecg_extended_extended.annotated_method_2.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "df_ecg_extended_extended['labelbox_diagnosis'] = df_ecg_extended_extended.iloc[:, 297:378].apply(lambda x: ','.join(x.index[x == 1]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Labels if they are accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_40_diagnosis = df_ecg_extended_extended[0:500000].loc[df_ecg_extended_extended['annotated_method_2']==1].labelbox_diagnosis.value_counts().head(80)\n",
    "\n",
    "# Get the diagnoses from rank 20 to 40\n",
    "diagnoses_20_to_40 = top_40_diagnosis.index[0:80]\n",
    "\n",
    "total_count = top_40_diagnosis.sum()\n",
    "\n",
    "for diagnosis in diagnoses_20_to_40:\n",
    "    count = top_40_diagnosis[diagnosis]\n",
    "    diagnosis_statement = df_ecg_extended_extended.loc[df_ecg_extended_extended['labelbox_diagnosis'] == diagnosis, 'diagnosis'].iloc[0]\n",
    "    percentage = (count / total_count) * 100\n",
    "    print(f\"Diagnosis: {diagnosis}\\nStatement: {diagnosis_statement}\\nFrequency: {count}\\nPercentage: {percentage:.2f}%\")\n",
    "    print(f\"Labelbox Diagnosis: {diagnosis}\\n\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(df_ecg_extended_extended.loc[df_ecg_extended_extended['Ventricular paced'] ==1][['RestingECG_PatientDemographics_PatientID','RestingECG_TestDemographics_AcquisitionDate','RestingECG_TestDemographics_AcquisitionTime','diagnosis', 'labelbox_diagnosis']].head(n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving dataset for dictionary processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ecg_extended_extended.to_parquet('/media/data1/ravram/ecg_temp_out.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
