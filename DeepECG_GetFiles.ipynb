{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.height', 1000)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"max_colwidth\", 200)\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"R_HOME\"] = \"/root/miniconda3/envs/R/lib/R\"\n",
    "\n",
    "import rpy2.robjects as objects\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "base = importr(\"base\")\n",
    "r_pROC = importr(\"pROC\")\n",
    "base._libPaths()[0]\n",
    "\n",
    "\n",
    "def df_stats(df):\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    print(\"\\n***** Shape: \", df.shape, \" *****\\n\")\n",
    "\n",
    "    columns_list = df.columns.values.tolist()\n",
    "    isnull_list = df.isnull().sum().values.tolist()\n",
    "    isunique_list = df.nunique().values.tolist()\n",
    "    dtypes_list = df.dtypes.tolist()\n",
    "\n",
    "    list_stat_val = list(zip(columns_list, isnull_list, isunique_list, dtypes_list))\n",
    "    df_stat_val = pd.DataFrame(\n",
    "        list_stat_val, columns=[\"Name\", \"Null\", \"Unique\", \"Dtypes\"]\n",
    "    )\n",
    "    print(tabulate(df_stat_val, headers=\"keys\", tablefmt=\"psql\"))\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### List all files in '/media/data1/muse_ge/ecg_retrospective' ending in XML and add them to list\n",
    "import glob\n",
    "import os\n",
    "\n",
    "## Get all fins in directory 'media/data1/muse_ge/ecg_retrospective' ending in .XML\n",
    "path = \"/media/data1/muse_ge/ecg_retrospective\"\n",
    "all_files = glob.glob(os.path.join(path, \"*.xml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create dataframe with all ECG files\n",
    "df = pd.DataFrame(all_files, columns=[\"path\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is muse_xml_to_array.py\n",
    "# Input a directory of XML files, get a directory of np arrays where each .npy is a 12-lead ecg shape 2500,12,1. So this gives you JUST the waveforms\n",
    "# Some notes, the unique ECG ID index key used in MUSE backend does not exist in the XML at least for us, so instead we use MRN_AcquisitionDTTM_PharmaUniqueECGID\n",
    "\n",
    "# In terminal run python3 muse_xml_to_array.py <LOCATION_OF_XML_FILES>\n",
    "\n",
    "import argparse\n",
    "import base64\n",
    "import os\n",
    "import struct\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xmltodict\n",
    "\n",
    "\n",
    "def file_path(path):\n",
    "    filepath = path\n",
    "    for dirName, subdirList, fileList in os.walk(filepath):\n",
    "        for filename in fileList:\n",
    "            if \".xml\" in filename.lower():\n",
    "                ekg_file_list.append(os.path.join(dirName, filename))\n",
    "\n",
    "\n",
    "# need to update this function to check the output directory for the output file and then only on newly added EKGs\n",
    "# add timestamp to start file string\n",
    "# this is annoying because the XML file name is a random timestamp and the output file is the UniqueECGID\n",
    "\n",
    "\n",
    "if not os.path.exists(os.getcwd() + \"/ekg_waveforms_output/\"):\n",
    "    os.mkdir(os.getcwd() + \"/ekg_waveforms_output/\")\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='Input and outputs for XML EKG parsing')\n",
    "# parser.add_argument('input', type=str)\n",
    "# parser.set_defaults(output=os.getcwd() + '/ekg_waveforms_output/') #ensure this directory already exists\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "def decode_ekg_muse(raw_wave):\n",
    "    \"\"\"\n",
    "    Ingest the base64 encoded waveforms and transform to numeric\n",
    "    \"\"\"\n",
    "    # covert the waveform from base64 to byte array\n",
    "    arr = base64.b64decode(bytes(raw_wave, \"utf-8\"))\n",
    "\n",
    "    # unpack every 2 bytes, little endian (16 bit encoding)\n",
    "    unpack_symbols = \"\".join([char * (len(arr) // 2) for char in \"h\"])\n",
    "    byte_array = struct.unpack(unpack_symbols, arr)\n",
    "    return byte_array\n",
    "\n",
    "\n",
    "def decode_ekg_muse_to_array(raw_wave, downsample=1):\n",
    "    \"\"\"\n",
    "    Ingest the base64 encoded waveforms and transform to numeric\n",
    "\n",
    "    downsample: 0.5 takes every other value in the array. Muse samples at 500/s and the sample model requires 250/s. So take every other.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dwnsmpl = int(1 // downsample)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"You must downsample by more than 0\")\n",
    "    # covert the waveform from base64 to byte array\n",
    "    arr = base64.b64decode(bytes(raw_wave, \"utf-8\"))\n",
    "\n",
    "    # unpack every 2 bytes, little endian (16 bit encoding)\n",
    "    unpack_symbols = \"\".join([char * int(len(arr) / 2) for char in \"h\"])\n",
    "    byte_array = struct.unpack(unpack_symbols, arr)\n",
    "    return np.array(byte_array)[::dwnsmpl]\n",
    "\n",
    "\n",
    "def xml_to_np_array_file(path_to_xml, path_to_output=os.getcwd()):\n",
    "\n",
    "    with open(path_to_xml, \"rb\") as fd:\n",
    "        dic = xmltodict.parse(fd.read().decode(\"utf8\"))\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    Upload the ECG as numpy array with shape=[2500,12,1] ([time, leads, 1]).\n",
    "\n",
    "    The voltage unit should be in 1 mv/unit and the sampling rate should be 250/second (total 10 second).\n",
    "\n",
    "    The leads should be ordered as follow I, II, III, aVR, aVL, aVF, V1, V2, V3, V4, V5, V6.\n",
    "\n",
    "    \"\"\"\n",
    "    # print(dic)\n",
    "    try:\n",
    "        pt_id = dic[\"RestingECG\"][\"PatientDemographics\"][\"PatientID\"]\n",
    "    except:\n",
    "        print(\"no PatientID\")\n",
    "        pt_id = \"none\"\n",
    "    try:\n",
    "        AcquisitionDateTime = (\n",
    "            dic[\"RestingECG\"][\"TestDemographics\"][\"AcquisitionDate\"]\n",
    "            + \"_\"\n",
    "            + dic[\"RestingECG\"][\"TestDemographics\"][\"AcquisitionTime\"].replace(\":\", \"-\")\n",
    "        )\n",
    "    except:\n",
    "        print(\"no AcquisitionDateTime\")\n",
    "        AcquisitionDateTime = \"none\"\n",
    "\n",
    "    # try:\n",
    "    #     requisition_number = dic['RestingECG']['Order']['RequisitionNumber']\n",
    "    # except:\n",
    "    #     print(\"no requisition_number\")\n",
    "    #     requisition_number = \"none\"\n",
    "\n",
    "    # need to instantiate leads in the proper order for the model\n",
    "    lead_order = [\n",
    "        \"I\",\n",
    "        \"II\",\n",
    "        \"III\",\n",
    "        \"aVR\",\n",
    "        \"aVL\",\n",
    "        \"aVF\",\n",
    "        \"V1\",\n",
    "        \"V2\",\n",
    "        \"V3\",\n",
    "        \"V4\",\n",
    "        \"V5\",\n",
    "        \"V6\",\n",
    "    ]\n",
    "\n",
    "    \"\"\"\n",
    "    Each EKG will have this data structure:\n",
    "    lead_data = {\n",
    "        'I': np.array\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    lead_data = dict.fromkeys(lead_order)\n",
    "    # lead_data = {leadid: None for k in lead_order}\n",
    "\n",
    "    #     for all_lead_data in dic['RestingECG']['Waveform']:\n",
    "    #         for single_lead_data in lead['LeadData']:\n",
    "    #             leadname =  single_lead_data['LeadID']\n",
    "    #             if leadname in (lead_order):\n",
    "    try:\n",
    "        for lead in dic[\"RestingECG\"][\"Waveform\"]:\n",
    "            for leadid in range(len(lead[\"LeadData\"])):\n",
    "                sample_length = len(\n",
    "                    decode_ekg_muse_to_array(lead[\"LeadData\"][leadid][\"WaveFormData\"])\n",
    "                )\n",
    "                # sample_length is equivalent to dic['RestingECG']['Waveform']['LeadData']['LeadSampleCountTotal']\n",
    "                if sample_length == 5000:\n",
    "                    lead_data[\n",
    "                        lead[\"LeadData\"][leadid][\"LeadID\"]\n",
    "                    ] = decode_ekg_muse_to_array(\n",
    "                        lead[\"LeadData\"][leadid][\"WaveFormData\"], downsample=0.5\n",
    "                    )\n",
    "                elif sample_length == 2500:\n",
    "                    lead_data[\n",
    "                        lead[\"LeadData\"][leadid][\"LeadID\"]\n",
    "                    ] = decode_ekg_muse_to_array(\n",
    "                        lead[\"LeadData\"][leadid][\"WaveFormData\"], downsample=1\n",
    "                    )\n",
    "                else:\n",
    "                    continue\n",
    "            # ensures all leads have 2500 samples and also passes over the 3 second waveform\n",
    "\n",
    "        lead_data[\"III\"] = np.array(lead_data[\"II\"]) - np.array(lead_data[\"I\"])\n",
    "        lead_data[\"aVR\"] = -(np.array(lead_data[\"I\"]) + np.array(lead_data[\"II\"])) / 2\n",
    "        lead_data[\"aVF\"] = (np.array(lead_data[\"II\"]) + np.array(lead_data[\"III\"])) / 2\n",
    "        lead_data[\"aVL\"] = (np.array(lead_data[\"I\"]) - np.array(lead_data[\"III\"])) / 2\n",
    "\n",
    "        lead_data = {k: lead_data[k] for k in lead_order}\n",
    "        # drops V3R, V4R, and V7 if it was a 15-lead ECG\n",
    "\n",
    "        # now construct and reshape the array\n",
    "        # converting the dictionary to an np.array\n",
    "        temp = []\n",
    "        for key, value in lead_data.items():\n",
    "            temp.append(value)\n",
    "\n",
    "        # transpose to be [time, leads, ]\n",
    "        ekg_array = np.array(temp).T\n",
    "\n",
    "        # expand dims to [time, leads, 1]\n",
    "        ekg_array = np.expand_dims(ekg_array, axis=-1)\n",
    "\n",
    "        # Here is a check to make sure all the model inputs are the right shape\n",
    "        #     assert ekg_array.shape == (2500, 12, 1), \"ekg_array is shape {} not (2500, 12, 1)\".format(ekg_array.shape )\n",
    "\n",
    "        # filename = '/ekg_waveform_{}_{}.npy'.format(pt_id, requisition_number)\n",
    "        filename = f\"{pt_id}_{AcquisitionDateTime}.npy\"\n",
    "\n",
    "        path_to_output += filename\n",
    "        # print(path_to_output)\n",
    "        with open(path_to_output, \"wb\") as f:\n",
    "            np.save(f, ekg_array)\n",
    "        return path_to_output\n",
    "\n",
    "    except:\n",
    "        print(\"error\", dic)\n",
    "        return None\n",
    "\n",
    "\n",
    "def ekg_batch_run(ekg_list):\n",
    "    i = 0\n",
    "    x = 0\n",
    "    for file in ekg_list:\n",
    "        try:\n",
    "            xml_to_np_array_file(file, output_dir)\n",
    "            i += 1\n",
    "        except Exception as e:\n",
    "            # print(\"file failed: \", file)\n",
    "            print(file, e)\n",
    "            x += 1\n",
    "        if i % 10000 == 0:\n",
    "            print(f\"Succesfully converted {i} EKGs, failed converting {x} EKGs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.getcwd() + \"/ekg_waveforms_output/\"\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ECGXMLReader import ECGXMLReader\n",
    "\n",
    "patientid_list = []\n",
    "patientage_list = []\n",
    "patient_date_of_birth_list = []\n",
    "patient_gender_list = []\n",
    "patient_VentricularRate_list = []\n",
    "patient_AtrialRate_list = []\n",
    "patient_PRInterval_list = []\n",
    "patient_QRSDuration_list = []\n",
    "patient_QTInterval_list = []\n",
    "patient_QTCorrected_list = []\n",
    "patient_Paxis_list = []\n",
    "patient_Raxis_list = []\n",
    "patient_TAxis_list = []\n",
    "patient_QRSCount_list = []\n",
    "patient_QOnset_list = []\n",
    "patient_QOffset_list = []\n",
    "patient_POnset_list = []\n",
    "patient_POffset_list = []\n",
    "patient_TOffset_list = []\n",
    "patient_ECGSampleBase_list = []\n",
    "patient_ECGSampleExponent_list = []\n",
    "patient_QTcFrederica_list = []\n",
    "patient_Location_list = []\n",
    "patient_LocatioName_list = []\n",
    "patient_RoomID_list = []\n",
    "patient_acquisitiondate_list = []\n",
    "patient_acquisitiontime_list = []\n",
    "patient_status_list = []\n",
    "patient_acquisitiondevice_list = []\n",
    "patient_referringMDLastName_list = []\n",
    "patient_AnalysisSoftware_list = []\n",
    "patient_acquisitionSoftwareVersion_list = []\n",
    "diagnosis_list = []\n",
    "original_diagnosis_list = []\n",
    "ecg_output_path_list = []\n",
    "xml_path_list = []\n",
    "\n",
    "for index, row in tqdm(df[1:1000].iterrows()):\n",
    "\n",
    "    ecg = ECGXMLReader(row[\"path\"], augmentLeads=True)\n",
    "    xml_path_list.append(row[\"path\"])\n",
    "    ### Concatenate dictionary keys self.ECG['RestingECG']['Diagnosis'] into a list\n",
    "    patientid_list.append(ecg.PatientDemographics[\"PatientID\"])\n",
    "\n",
    "    try:\n",
    "        patientage_list.append(ecg.PatientDemographics[\"PatientAge\"])\n",
    "    except:\n",
    "        patientage_list.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        patient_date_of_birth_list.append(ecg.PatientDemographics[\"DateofBirth\"])\n",
    "    except:\n",
    "        patient_date_of_birth_list.append(np.nan)\n",
    "    try:\n",
    "        patient_gender_list.append(ecg.PatientDemographics[\"Gender\"])\n",
    "    except:\n",
    "        patient_gender_list.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        patient_VentricularRate_list.append(\n",
    "            ecg.RestingECGMeasurements[\"VentricularRate\"]\n",
    "        )\n",
    "    except:\n",
    "        patient_VentricularRate_list.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        patient_AtrialRate_list.append(ecg.RestingECGMeasurements[\"AtrialRate\"])\n",
    "    except:\n",
    "        patient_AtrialRate_list.append(np.nan)\n",
    "    try:\n",
    "        patient_PRInterval_list.append(ecg.RestingECGMeasurements[\"PRInterval\"])\n",
    "    except:\n",
    "        patient_PRInterval_list.append(np.nan)\n",
    "    try:\n",
    "        patient_QRSDuration_list.append(ecg.RestingECGMeasurements[\"QRSDuration\"])\n",
    "    except:\n",
    "        patient_QRSDuration_list.append(np.nan)\n",
    "    try:\n",
    "        patient_QTInterval_list.append(ecg.RestingECGMeasurements[\"QTInterval\"])\n",
    "    except:\n",
    "        patient_QTInterval_list.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        patient_QTCorrected_list.append(ecg.RestingECGMeasurements[\"QTCorrected\"])\n",
    "    except:\n",
    "        patient_QTCorrected_list.append(np.nan)\n",
    "    try:\n",
    "        patient_Paxis_list.append(ecg.RestingECGMeasurements[\"PAxis\"])\n",
    "    except:\n",
    "        patient_Paxis_list.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        patient_Raxis_list.append(ecg.RestingECGMeasurements[\"RAxis\"])\n",
    "    except:\n",
    "        patient_Raxis_list.append(np.nan)\n",
    "    try:\n",
    "        patient_TAxis_list.append(ecg.RestingECGMeasurements[\"TAxis\"])\n",
    "    except:\n",
    "        patient_TAxis_list.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        patient_QRSCount_list.append(ecg.RestingECGMeasurements[\"QRSCount\"])\n",
    "    except:\n",
    "        patient_QRSCount_list.append(np.nan)\n",
    "    try:\n",
    "        patient_QOnset_list.append(ecg.RestingECGMeasurements[\"QOnset\"])\n",
    "    except:\n",
    "        patient_QOnset_list.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        patient_QOffset_list.append(ecg.RestingECGMeasurements[\"QOffset\"])\n",
    "    except:\n",
    "        patient_QOffset_list.append(np.nan)\n",
    "    try:\n",
    "        patient_POnset_list.append(ecg.RestingECGMeasurements[\"POnset\"])\n",
    "    except:\n",
    "        patient_POnset_list.append(np.nan)\n",
    "    try:\n",
    "        patient_POffset_list.append(ecg.RestingECGMeasurements[\"POffset\"])\n",
    "    except:\n",
    "        patient_POffset_list.append(np.nan)\n",
    "    try:\n",
    "        patient_TOffset_list.append(ecg.RestingECGMeasurements[\"TOffset\"])\n",
    "    except:\n",
    "        patient_TOffset_list.append(np.nan)\n",
    "\n",
    "    patient_ECGSampleBase_list.append(ecg.RestingECGMeasurements[\"ECGSampleBase\"])\n",
    "    patient_ECGSampleExponent_list.append(\n",
    "        ecg.RestingECGMeasurements[\"ECGSampleExponent\"]\n",
    "    )\n",
    "    try:\n",
    "        patient_QTcFrederica_list.append(ecg.RestingECGMeasurements[\"QTcFrederica\"])\n",
    "    except:\n",
    "        patient_QTcFrederica_list.append(np.nan)\n",
    "\n",
    "    patient_Location_list.append(ecg.TestDemographics[\"Location\"])\n",
    "\n",
    "    try:\n",
    "        patient_LocatioName_list.append(ecg.TestDemographics[\"LocationName\"])\n",
    "    except:\n",
    "        patient_LocatioName_list.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        patient_RoomID_list.append(ecg.TestDemographics[\"RoomID\"])\n",
    "    except:\n",
    "        patient_RoomID_list.append(\"None\")\n",
    "    try:\n",
    "        patient_acquisitiondate_list.append(ecg.TestDemographics[\"AcquisitionDate\"])\n",
    "    except:\n",
    "        patient_acquisitiondate_list.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        patient_acquisitiontime_list.append(ecg.TestDemographics[\"AcquisitionTime\"])\n",
    "    except:\n",
    "        patient_acquisitiontime_list.append(np.nan)\n",
    "\n",
    "    patient_status_list.append(ecg.TestDemographics[\"Status\"])\n",
    "\n",
    "    try:\n",
    "        patient_acquisitiondevice_list.append(ecg.TestDemographics[\"AcquisitionDevice\"])\n",
    "    except:\n",
    "        patient_acquisitiondevice_list.append(np.nan)\n",
    "\n",
    "    try:\n",
    "        patient_referringMDLastName_list.append(\n",
    "            ecg.TestDemographics[\"ReferringMDLastName\"]\n",
    "        )\n",
    "    except:\n",
    "        patient_referringMDLastName_list.append(\"None\")\n",
    "    try:\n",
    "        patient_AnalysisSoftware_list.append(\n",
    "            ecg.TestDemographics[\"AnalysisSoftwareVersion\"]\n",
    "        )\n",
    "    except:\n",
    "        patient_AnalysisSoftware_list.append(np.nan)\n",
    "    try:\n",
    "        patient_acquisitionSoftwareVersion_list.append(\n",
    "            ecg.TestDemographics[\"AcquisitionSoftwareVersion\"]\n",
    "        )\n",
    "    except:\n",
    "        patient_acquisitionSoftwareVersion_list.append(np.nan)\n",
    "\n",
    "    diagnosis = []\n",
    "    try:\n",
    "        for key in ecg.Diagnosis[\"DiagnosisStatement\"]:\n",
    "            # print(key['StmtText'])\n",
    "            try:\n",
    "                diagnosis.append(key[\"StmtText\"])\n",
    "            except:\n",
    "                diagnosis.append(key[\"ENDSLINE\"])\n",
    "\n",
    "        ##merge items in diagnosis list into a single string\n",
    "        diagnosis = \" \".join(diagnosis)\n",
    "\n",
    "        diagnosis_list.append(diagnosis)\n",
    "    except:\n",
    "        print(ecg.TestDemographics)\n",
    "        print(ecg.PatientDemographics)\n",
    "        print(ecg.RestingECGMeasurements)\n",
    "        print(ecg.PatientDemographics[\"PatientID\"])\n",
    "        diagnosis_list.append(-1)\n",
    "\n",
    "    diagnosis = []\n",
    "    try:\n",
    "        for key in ecg.OriginalDiagnosis[\"DiagnosisStatement\"]:\n",
    "            # print(key['StmtText'])\n",
    "            try:\n",
    "                diagnosis.append(key[\"StmtText\"])\n",
    "            except:\n",
    "                diagnosis.append(key[\"ENDSLINE\"])\n",
    "\n",
    "        ##merge items in diagnosis list into a single string\n",
    "        diagnosis = \" \".join(diagnosis)\n",
    "\n",
    "        original_diagnosis_list.append(diagnosis)\n",
    "    except:\n",
    "        print(ecg.TestDemographics)\n",
    "        print(ecg.PatientDemographics)\n",
    "        print(ecg.RestingECGMeasurements)\n",
    "        print(ecg.PatientDemographics[\"PatientID\"])\n",
    "        original_diagnosis_list.append(-1)\n",
    "\n",
    "        # display(ecg.Diagnosis['DiagnosisStatement'])\n",
    "        # break\n",
    "    # print(ecg.TestDemographics)\n",
    "    # print(ecg.PatientDemographics)\n",
    "    # print(ecg.RestingECGMeasurements)\n",
    "    # print(ecg.Diagnosis)\n",
    "    # print(ecg.OriginalDiagnosis)\n",
    "    ecg_output_path = xml_to_np_array_file(row[\"path\"], output_dir)\n",
    "    ecg_output_path_list.append(ecg_output_path)\n",
    "##Create dataaframe with the previous lists\n",
    "df_output = pd.DataFrame(\n",
    "    {\n",
    "        \"patientid\": patientid_list,\n",
    "        \"age\": patientage_list,\n",
    "        \"dob\": patient_date_of_birth_list,\n",
    "        \"gender\": patient_gender_list,\n",
    "        \"VentricularRate\": patient_VentricularRate_list,\n",
    "        \"AtrialRate\": patient_AtrialRate_list,\n",
    "        \"PRInterval\": patient_PRInterval_list,\n",
    "        \"QRSDuration\": patient_QRSDuration_list,\n",
    "        \"QTInterval\": patient_QTInterval_list,\n",
    "        \"QTCorrected\": patient_QTCorrected_list,\n",
    "        \"PAxis\": patient_Paxis_list,\n",
    "        \"RAXis\": patient_Raxis_list,\n",
    "        \"TAxis\": patient_TAxis_list,\n",
    "        \"QRSCount\": patient_QRSCount_list,\n",
    "        \"QOnset\": patient_QOnset_list,\n",
    "        \"QOffset\": patient_QOffset_list,\n",
    "        \"POnset\": patient_POnset_list,\n",
    "        \"POffset\": patient_POffset_list,\n",
    "        \"TOffset\": patient_TOffset_list,\n",
    "        \"ECGSampleBase\": patient_ECGSampleBase_list,\n",
    "        \"ECGSampleExponent\": patient_ECGSampleExponent_list,\n",
    "        \"QTcFrederica\": patient_QTcFrederica_list,\n",
    "        \"Location\": patient_Location_list,\n",
    "        \"LocationName\": patient_LocatioName_list,\n",
    "        \"RoomID\": patient_RoomID_list,\n",
    "        \"AcquisitionDate\": patient_acquisitiondate_list,\n",
    "        \"AcquisitionTime\": patient_acquisitiontime_list,\n",
    "        \"Status\": patient_status_list,\n",
    "        \"AcquisitionDevice\": patient_acquisitiondevice_list,\n",
    "        \"ReferringMDLastName\": patient_referringMDLastName_list,\n",
    "        \"AnalysisSoftware\": patient_AnalysisSoftware_list,\n",
    "        \"AcquisitionSoftwareVersion\": patient_acquisitionSoftwareVersion_list,\n",
    "        \"Diagnosis\": diagnosis_list,\n",
    "        \"Original_Diagnosis\": original_diagnosis_list,\n",
    "        \"xml_path\": xml_path_list,\n",
    "        \"ecg_output_path\": ecg_output_path_list,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = (\n",
    "    df_output.groupby([\"patientid\", \"AcquisitionDate\", \"AcquisitionTime\"])\n",
    "    .first()\n",
    "    .reset_index()\n",
    ")\n",
    "display(df_stats(df_output))\n",
    "display(df_stats(df_m))\n",
    "## The ECGs can be grouped by patient id, date and time to have a 1 unique row per ECG - this means the filename to save the ECG also needs to have the date and time in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir = os.getcwd() + '/ekg_waveforms_output/'\n",
    "# ekg_batch_run(df['path'][0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display ECG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npyfilespath = os.getcwd() + \"/ekg_waveforms_output/\"\n",
    "os.chdir(npyfilespath)\n",
    "npfiles = glob.glob(\"*.npy\")\n",
    "npfiles.sort()\n",
    "all_arrays_train = []\n",
    "# all_arrays_eval = []\n",
    "\n",
    "# If trying to test model quickly use smaller total dataset or change dataloader to load npy file batch by batch\n",
    "\n",
    "# Not rewriting stacked array so below is commented out\n",
    "\n",
    "for i, npfile in enumerate(npfiles):\n",
    "    x = 0\n",
    "    i = 0\n",
    "    try:\n",
    "        path = os.path.join(npyfilespath + npfile)\n",
    "        file = np.load(path)\n",
    "\n",
    "        file = np.reshape(file, (1, 2500, 12))\n",
    "        all_arrays_train.append(file)\n",
    "        x += 1\n",
    "        i += 1\n",
    "    except:\n",
    "        continue\n",
    "    if i % 1 == 100:\n",
    "        print(\"{i} EKGs have been written to array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(all_arrays_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_arrays_train = np.array(all_arrays_train)\n",
    "reshaped = np.reshape(all_arrays_train, (all_arrays_train.shape[0], 2500, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(npyfilespath + npfile)\n",
    "file = np.load(path)\n",
    "\n",
    "file = np.reshape(file, (1, 2500, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reconstruct the 12 lead ecg from the array\n",
    "lead_order = [\"I\", \"II\", \"III\", \"aVR\", \"aVL\", \"aVF\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\"]\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 9]\n",
    "fig, axs = plt.subplots(len(lead_order))\n",
    "for i in range(0, 12):\n",
    "    axs[i].plot(reshaped[0][:, i])\n",
    "    axs[i].set(ylabel=str(lead_order[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To reconstruct the 12 lead ecg from the array\n",
    "lead_order = [\"I\", \"II\", \"III\", \"aVR\", \"aVL\", \"aVF\", \"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V6\"]\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 9]\n",
    "fig, axs = plt.subplots(len(lead_order))\n",
    "for i in range(0, 12):\n",
    "    axs[i].plot(reshaped[2][:, i])\n",
    "    axs[i].set(ylabel=str(lead_order[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
