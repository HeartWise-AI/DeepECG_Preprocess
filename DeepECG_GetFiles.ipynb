{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.height', 1000)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"max_colwidth\", 200)\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"R_HOME\"] = \"/root/miniconda3/envs/R/lib/R\"\n",
    "\n",
    "import rpy2.robjects as objects\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "base = importr(\"base\")\n",
    "r_pROC = importr(\"pROC\")\n",
    "base._libPaths()[0]\n",
    "\n",
    "\n",
    "def df_stats(df):\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    print(\"\\n***** Shape: \", df.shape, \" *****\\n\")\n",
    "\n",
    "    columns_list = df.columns.values.tolist()\n",
    "    isnull_list = df.isnull().sum().values.tolist()\n",
    "    isunique_list = df.nunique().values.tolist()\n",
    "    dtypes_list = df.dtypes.tolist()\n",
    "\n",
    "    list_stat_val = list(zip(columns_list, isnull_list, isunique_list, dtypes_list))\n",
    "    df_stat_val = pd.DataFrame(\n",
    "        list_stat_val, columns=[\"Name\", \"Null\", \"Unique\", \"Dtypes\"]\n",
    "    )\n",
    "    print(tabulate(df_stat_val, headers=\"keys\", tablefmt=\"psql\"))\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is muse_xml_to_array.py\n",
    "# Input a directory of XML files, get a directory of np arrays where each .npy is a 12-lead ecg shape 2500,12,1. So this gives you JUST the waveforms\n",
    "# Some notes, the unique ECG ID index key used in MUSE backend does not exist in the XML at least for us, so instead we use MRN_AcquisitionDTTM_PharmaUniqueECGID\n",
    "\n",
    "# In terminal run python3 muse_xml_to_array.py <LOCATION_OF_XML_FILES>\n",
    "\n",
    "import argparse\n",
    "import base64\n",
    "import os\n",
    "import struct\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xmltodict\n",
    "\n",
    "\n",
    "def file_path(path):\n",
    "    filepath = path\n",
    "    for dirName, subdirList, fileList in os.walk(filepath):\n",
    "        for filename in fileList:\n",
    "            if \".xml\" in filename.lower():\n",
    "                ekg_file_list.append(os.path.join(dirName, filename))\n",
    "\n",
    "\n",
    "# need to update this function to check the output directory for the output file and then only on newly added EKGs\n",
    "# add timestamp to start file string\n",
    "# this is annoying because the XML file name is a random timestamp and the output file is the UniqueECGID\n",
    "\n",
    "\n",
    "if not os.path.exists(os.getcwd() + \"/ekg_waveforms_output/\"):\n",
    "    os.mkdir(os.getcwd() + \"/ekg_waveforms_output/\")\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='Input and outputs for XML EKG parsing')\n",
    "# parser.add_argument('input', type=str)\n",
    "# parser.set_defaults(output=os.getcwd() + '/ekg_waveforms_output/') #ensure this directory already exists\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "def decode_ekg_muse(raw_wave):\n",
    "    \"\"\"\n",
    "    Ingest the base64 encoded waveforms and transform to numeric\n",
    "    \"\"\"\n",
    "    # covert the waveform from base64 to byte array\n",
    "    arr = base64.b64decode(bytes(raw_wave, \"utf-8\"))\n",
    "\n",
    "    # unpack every 2 bytes, little endian (16 bit encoding)\n",
    "    unpack_symbols = \"\".join([char * (len(arr) // 2) for char in \"h\"])\n",
    "    byte_array = struct.unpack(unpack_symbols, arr)\n",
    "    return byte_array\n",
    "\n",
    "\n",
    "def decode_ekg_muse_to_array(raw_wave, downsample=1):\n",
    "    \"\"\"\n",
    "    Ingest the base64 encoded waveforms and transform to numeric\n",
    "\n",
    "    downsample: 0.5 takes every other value in the array. Muse samples at 500/s and the sample model requires 250/s. So take every other.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dwnsmpl = int(1 // downsample)\n",
    "    except ZeroDivisionError:\n",
    "        print(\"You must downsample by more than 0\")\n",
    "    # covert the waveform from base64 to byte array\n",
    "    arr = base64.b64decode(bytes(raw_wave, \"utf-8\"))\n",
    "\n",
    "    # unpack every 2 bytes, little endian (16 bit encoding)\n",
    "    unpack_symbols = \"\".join([char * int(len(arr) / 2) for char in \"h\"])\n",
    "    byte_array = struct.unpack(unpack_symbols, arr)\n",
    "    return np.array(byte_array)[::dwnsmpl]\n",
    "\n",
    "\n",
    "def xml_to_np_array_file(path_to_xml, path_to_output=os.getcwd()):\n",
    "\n",
    "    with open(path_to_xml, \"rb\") as fd:\n",
    "        dic = xmltodict.parse(fd.read().decode(\"utf8\"))\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    Upload the ECG as numpy array with shape=[2500,12,1] ([time, leads, 1]).\n",
    "\n",
    "    The voltage unit should be in 1 mv/unit and the sampling rate should be 250/second (total 10 second).\n",
    "\n",
    "    The leads should be ordered as follow I, II, III, aVR, aVL, aVF, V1, V2, V3, V4, V5, V6.\n",
    "\n",
    "    \"\"\"\n",
    "    # print(dic)\n",
    "    try:\n",
    "        pt_id = dic[\"RestingECG\"][\"PatientDemographics\"][\"PatientID\"]\n",
    "    except:\n",
    "        print(\"no PatientID\")\n",
    "        pt_id = \"none\"\n",
    "    try:\n",
    "        AcquisitionDateTime = (\n",
    "            dic[\"RestingECG\"][\"TestDemographics\"][\"AcquisitionDate\"]\n",
    "            + \"_\"\n",
    "            + dic[\"RestingECG\"][\"TestDemographics\"][\"AcquisitionTime\"].replace(\":\", \"-\")\n",
    "        )\n",
    "    except:\n",
    "        print(\"no AcquisitionDateTime\")\n",
    "        AcquisitionDateTime = \"none\"\n",
    "\n",
    "    # try:\n",
    "    #     requisition_number = dic['RestingECG']['Order']['RequisitionNumber']\n",
    "    # except:\n",
    "    #     print(\"no requisition_number\")\n",
    "    #     requisition_number = \"none\"\n",
    "\n",
    "    # need to instantiate leads in the proper order for the model\n",
    "    lead_order = [\n",
    "        \"I\",\n",
    "        \"II\",\n",
    "        \"III\",\n",
    "        \"aVR\",\n",
    "        \"aVL\",\n",
    "        \"aVF\",\n",
    "        \"V1\",\n",
    "        \"V2\",\n",
    "        \"V3\",\n",
    "        \"V4\",\n",
    "        \"V5\",\n",
    "        \"V6\",\n",
    "    ]\n",
    "\n",
    "    \"\"\"\n",
    "    Each EKG will have this data structure:\n",
    "    lead_data = {\n",
    "        'I': np.array\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    lead_data = dict.fromkeys(lead_order)\n",
    "    # lead_data = {leadid: None for k in lead_order}\n",
    "\n",
    "    #     for all_lead_data in dic['RestingECG']['Waveform']:\n",
    "    #         for single_lead_data in lead['LeadData']:\n",
    "    #             leadname =  single_lead_data['LeadID']\n",
    "    #             if leadname in (lead_order):\n",
    "    #try:\n",
    "        for lead in dic[\"RestingECG\"][\"Waveform\"]:\n",
    "            for leadid in range(len(lead[\"LeadData\"])):\n",
    "                sample_length = len(\n",
    "                    decode_ekg_muse_to_array(lead[\"LeadData\"][leadid][\"WaveFormData\"])\n",
    "                )\n",
    "                # sample_length is equivalent to dic['RestingECG']['Waveform']['LeadData']['LeadSampleCountTotal']\n",
    "                if sample_length == 5000:\n",
    "                    lead_data[\n",
    "                        lead[\"LeadData\"][leadid][\"LeadID\"]\n",
    "                    ] = decode_ekg_muse_to_array(\n",
    "                        lead[\"LeadData\"][leadid][\"WaveFormData\"], downsample=0.5\n",
    "                    )\n",
    "                elif sample_length == 2500:\n",
    "                    lead_data[\n",
    "                        lead[\"LeadData\"][leadid][\"LeadID\"]\n",
    "                    ] = decode_ekg_muse_to_array(\n",
    "                        lead[\"LeadData\"][leadid][\"WaveFormData\"], downsample=1\n",
    "                    )\n",
    "                else:\n",
    "                    continue\n",
    "            # ensures all leads have 2500 samples and also passes over the 3 second waveform\n",
    "\n",
    "        lead_data[\"III\"] = np.array(lead_data[\"II\"]) - np.array(lead_data[\"I\"])\n",
    "        lead_data[\"aVR\"] = -(np.array(lead_data[\"I\"]) + np.array(lead_data[\"II\"])) / 2\n",
    "        lead_data[\"aVF\"] = (np.array(lead_data[\"II\"]) + np.array(lead_data[\"III\"])) / 2\n",
    "        lead_data[\"aVL\"] = (np.array(lead_data[\"I\"]) - np.array(lead_data[\"III\"])) / 2\n",
    "\n",
    "        lead_data = {k: lead_data[k] for k in lead_order}\n",
    "        # drops V3R, V4R, and V7 if it was a 15-lead ECG\n",
    "\n",
    "        # now construct and reshape the array\n",
    "        # converting the dictionary to an np.array\n",
    "        temp = []\n",
    "        for key, value in lead_data.items():\n",
    "            temp.append(value)\n",
    "\n",
    "        # transpose to be [time, leads, ]\n",
    "        ekg_array = np.array(temp).T\n",
    "\n",
    "        # expand dims to [time, leads, 1]\n",
    "        ekg_array = np.expand_dims(ekg_array, axis=-1)\n",
    "\n",
    "        # Here is a check to make sure all the model inputs are the right shape\n",
    "        #     assert ekg_array.shape == (2500, 12, 1), \"ekg_array is shape {} not (2500, 12, 1)\".format(ekg_array.shape )\n",
    "\n",
    "        # filename = '/ekg_waveform_{}_{}.npy'.format(pt_id, requisition_number)\n",
    "        filename = f\"{pt_id}_{AcquisitionDateTime}.npy\"\n",
    "\n",
    "        path_to_output += filename\n",
    "        # print(path_to_output)\n",
    "        with open(path_to_output, \"wb\") as f:\n",
    "            np.save(f, ekg_array)\n",
    "        return path_to_output\n",
    "\n",
    "    #except:\n",
    "    #    print(\"error\", dic)\n",
    "    #    return None\n",
    "\n",
    "\n",
    "def ekg_batch_run(ekg_list):\n",
    "    i = 0\n",
    "    x = 0\n",
    "    for file in ekg_list:\n",
    "        try:\n",
    "            xml_to_np_array_file(file, output_dir)\n",
    "            i += 1\n",
    "        except Exception as e:\n",
    "            # print(\"file failed: \", file)\n",
    "            print(file, e)\n",
    "            x += 1\n",
    "        if i % 10000 == 0:\n",
    "            print(f\"Succesfully converted {i} EKGs, failed converting {x} EKGs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ecg_dataframe_and_npy(df, output_dir=\"/ekg_waveforms_output/\"):\n",
    "    output_dir = os.getcwd() + output_dir\n",
    "\n",
    "    from ECGXMLReader import ECGXMLReader\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    patientid_list = []\n",
    "    patientage_list = []\n",
    "    patient_date_of_birth_list = []\n",
    "    patient_gender_list = []\n",
    "    patient_VentricularRate_list = []\n",
    "    patient_AtrialRate_list = []\n",
    "    patient_PRInterval_list = []\n",
    "    patient_QRSDuration_list = []\n",
    "    patient_QTInterval_list = []\n",
    "    patient_QTCorrected_list = []\n",
    "    patient_Paxis_list = []\n",
    "    patient_Raxis_list = []\n",
    "    patient_TAxis_list = []\n",
    "    patient_QRSCount_list = []\n",
    "    patient_QOnset_list = []\n",
    "    patient_QOffset_list = []\n",
    "    patient_POnset_list = []\n",
    "    patient_POffset_list = []\n",
    "    patient_TOffset_list = []\n",
    "    patient_ECGSampleBase_list = []\n",
    "    patient_ECGSampleExponent_list = []\n",
    "    patient_QTcFrederica_list = []\n",
    "    patient_Location_list = []\n",
    "    patient_LocatioName_list = []\n",
    "    patient_RoomID_list = []\n",
    "    patient_acquisitiondate_list = []\n",
    "    patient_acquisitiontime_list = []\n",
    "    patient_status_list = []\n",
    "    patient_acquisitiondevice_list = []\n",
    "    patient_referringMDLastName_list = []\n",
    "    patient_AnalysisSoftware_list = []\n",
    "    patient_acquisitionSoftwareVersion_list = []\n",
    "    diagnosis_list = []\n",
    "    original_diagnosis_list = []\n",
    "    ecg_output_path_list = []\n",
    "    xml_path_list = []\n",
    "\n",
    "    for index, row in tqdm(df.iterrows()):\n",
    "        ecg = ECGXMLReader(row[\"path\"], augmentLeads=True)\n",
    "        xml_path_list.append(row[\"path\"])\n",
    "        ### Concatenate dictionary keys self.ECG['RestingECG']['Diagnosis'] into a list\n",
    "        patientid_list.append(ecg.PatientDemographics[\"PatientID\"])\n",
    "\n",
    "        try:\n",
    "            patientage_list.append(ecg.PatientDemographics[\"PatientAge\"])\n",
    "        except:\n",
    "            patientage_list.append(np.nan)\n",
    "\n",
    "        try:\n",
    "            patient_date_of_birth_list.append(ecg.PatientDemographics[\"DateofBirth\"])\n",
    "        except:\n",
    "            patient_date_of_birth_list.append(np.nan)\n",
    "        try:\n",
    "            patient_gender_list.append(ecg.PatientDemographics[\"Gender\"])\n",
    "        except:\n",
    "            patient_gender_list.append(np.nan)\n",
    "\n",
    "        try:\n",
    "            patient_VentricularRate_list.append(\n",
    "                ecg.RestingECGMeasurements[\"VentricularRate\"]\n",
    "            )\n",
    "        except:\n",
    "            patient_VentricularRate_list.append(np.nan)\n",
    "\n",
    "        try:\n",
    "            patient_AtrialRate_list.append(ecg.RestingECGMeasurements[\"AtrialRate\"])\n",
    "        except:\n",
    "            patient_AtrialRate_list.append(np.nan)\n",
    "        try:\n",
    "            patient_PRInterval_list.append(ecg.RestingECGMeasurements[\"PRInterval\"])\n",
    "        except:\n",
    "            patient_PRInterval_list.append(np.nan)\n",
    "        try:\n",
    "            patient_QRSDuration_list.append(ecg.RestingECGMeasurements[\"QRSDuration\"])\n",
    "        except:\n",
    "            patient_QRSDuration_list.append(np.nan)\n",
    "        try:\n",
    "            patient_QTInterval_list.append(ecg.RestingECGMeasurements[\"QTInterval\"])\n",
    "        except:\n",
    "            patient_QTInterval_list.append(np.nan)\n",
    "\n",
    "        try:\n",
    "            patient_QTCorrected_list.append(ecg.RestingECGMeasurements[\"QTCorrected\"])\n",
    "        except:\n",
    "            patient_QTCorrected_list.append(np.nan)\n",
    "        try:\n",
    "            patient_Paxis_list.append(ecg.RestingECGMeasurements[\"PAxis\"])\n",
    "        except:\n",
    "            patient_Paxis_list.append(np.nan)\n",
    "\n",
    "        try:\n",
    "            patient_Raxis_list.append(ecg.RestingECGMeasurements[\"RAxis\"])\n",
    "        except:\n",
    "            patient_Raxis_list.append(np.nan)\n",
    "        try:\n",
    "            patient_TAxis_list.append(ecg.RestingECGMeasurements[\"TAxis\"])\n",
    "        except:\n",
    "            patient_TAxis_list.append(np.nan)\n",
    "\n",
    "        try:\n",
    "            patient_QRSCount_list.append(ecg.RestingECGMeasurements[\"QRSCount\"])\n",
    "        except:\n",
    "            patient_QRSCount_list.append(np.nan)\n",
    "        try:\n",
    "            patient_QOnset_list.append(ecg.RestingECGMeasurements[\"QOnset\"])\n",
    "        except:\n",
    "            patient_QOnset_list.append(np.nan)\n",
    "\n",
    "        try:\n",
    "            patient_QOffset_list.append(ecg.RestingECGMeasurements[\"QOffset\"])\n",
    "        except:\n",
    "            patient_QOffset_list.append(np.nan)\n",
    "        try:\n",
    "            patient_POnset_list.append(ecg.RestingECGMeasurements[\"POnset\"])\n",
    "        except:\n",
    "            patient_POnset_list.append(np.nan)\n",
    "        try:\n",
    "            patient_POffset_list.append(ecg.RestingECGMeasurements[\"POffset\"])\n",
    "        except:\n",
    "            patient_POffset_list.append(np.nan)\n",
    "        try:\n",
    "            patient_TOffset_list.append(ecg.RestingECGMeasurements[\"TOffset\"])\n",
    "        except:\n",
    "            patient_TOffset_list.append(np.nan)\n",
    "\n",
    "        patient_ECGSampleBase_list.append(ecg.RestingECGMeasurements[\"ECGSampleBase\"])\n",
    "        patient_ECGSampleExponent_list.append(\n",
    "            ecg.RestingECGMeasurements[\"ECGSampleExponent\"]\n",
    "        )\n",
    "        try:\n",
    "            patient_QTcFrederica_list.append(ecg.RestingECGMeasurements[\"QTcFrederica\"])\n",
    "        except:\n",
    "            patient_QTcFrederica_list.append(np.nan)\n",
    "\n",
    "        patient_Location_list.append(ecg.TestDemographics[\"Location\"])\n",
    "\n",
    "        try:\n",
    "            patient_LocatioName_list.append(ecg.TestDemographics[\"LocationName\"])\n",
    "        except:\n",
    "            patient_LocatioName_list.append(np.nan)\n",
    "\n",
    "        try:\n",
    "            patient_RoomID_list.append(ecg.TestDemographics[\"RoomID\"])\n",
    "        except:\n",
    "            patient_RoomID_list.append(\"None\")\n",
    "        try:\n",
    "            patient_acquisitiondate_list.append(ecg.TestDemographics[\"AcquisitionDate\"])\n",
    "        except:\n",
    "            patient_acquisitiondate_list.append(np.nan)\n",
    "\n",
    "        try:\n",
    "            patient_acquisitiontime_list.append(ecg.TestDemographics[\"AcquisitionTime\"])\n",
    "        except:\n",
    "            patient_acquisitiontime_list.append(np.nan)\n",
    "\n",
    "        patient_status_list.append(ecg.TestDemographics[\"Status\"])\n",
    "\n",
    "        try:\n",
    "            patient_acquisitiondevice_list.append(\n",
    "                ecg.TestDemographics[\"AcquisitionDevice\"]\n",
    "            )\n",
    "        except:\n",
    "            patient_acquisitiondevice_list.append(np.nan)\n",
    "\n",
    "        try:\n",
    "            patient_referringMDLastName_list.append(\n",
    "                ecg.TestDemographics[\"ReferringMDLastName\"]\n",
    "            )\n",
    "        except:\n",
    "            patient_referringMDLastName_list.append(\"None\")\n",
    "        try:\n",
    "            patient_AnalysisSoftware_list.append(\n",
    "                ecg.TestDemographics[\"AnalysisSoftwareVersion\"]\n",
    "            )\n",
    "        except:\n",
    "            patient_AnalysisSoftware_list.append(np.nan)\n",
    "        try:\n",
    "            patient_acquisitionSoftwareVersion_list.append(\n",
    "                ecg.TestDemographics[\"AcquisitionSoftwareVersion\"]\n",
    "            )\n",
    "        except:\n",
    "            patient_acquisitionSoftwareVersion_list.append(np.nan)\n",
    "\n",
    "        diagnosis = []\n",
    "        try:\n",
    "            for key in ecg.Diagnosis[\"DiagnosisStatement\"]:\n",
    "                # print(key['StmtText'])\n",
    "                try:\n",
    "                    diagnosis.append(key[\"StmtText\"])\n",
    "                except:\n",
    "                    diagnosis.append(key[\"ENDSLINE\"])\n",
    "\n",
    "            ##merge items in diagnosis list into a single string\n",
    "            diagnosis = \" \".join(diagnosis)\n",
    "\n",
    "            diagnosis_list.append(diagnosis)\n",
    "        except:\n",
    "            print(ecg.TestDemographics)\n",
    "            print(ecg.PatientDemographics)\n",
    "            print(ecg.RestingECGMeasurements)\n",
    "            print(ecg.PatientDemographics[\"PatientID\"])\n",
    "            diagnosis_list.append(-1)\n",
    "\n",
    "        diagnosis = []\n",
    "        try:\n",
    "            for key in ecg.OriginalDiagnosis[\"DiagnosisStatement\"]:\n",
    "                # print(key['StmtText'])\n",
    "                try:\n",
    "                    diagnosis.append(key[\"StmtText\"])\n",
    "                except:\n",
    "                    diagnosis.append(key[\"ENDSLINE\"])\n",
    "\n",
    "            ##merge items in diagnosis list into a single string\n",
    "            diagnosis = \" \".join(diagnosis)\n",
    "\n",
    "            original_diagnosis_list.append(diagnosis)\n",
    "        except:\n",
    "            print(ecg.TestDemographics)\n",
    "            print(ecg.PatientDemographics)\n",
    "            print(ecg.RestingECGMeasurements)\n",
    "            print(ecg.PatientDemographics[\"PatientID\"])\n",
    "            original_diagnosis_list.append(-1)\n",
    "\n",
    "            # display(ecg.Diagnosis['DiagnosisStatement'])\n",
    "            # break\n",
    "        # print(ecg.TestDemographics)\n",
    "        # print(ecg.PatientDemographics)\n",
    "        # print(ecg.RestingECGMeasurements)\n",
    "        # print(ecg.Diagnosis)\n",
    "        # print(ecg.OriginalDiagnosis)\n",
    "        ecg_output_path = xml_to_np_array_file(row[\"path\"], output_dir)\n",
    "        ecg_output_path_list.append(ecg_output_path)\n",
    "    ##Create dataaframe with the previous lists\n",
    "    df_output = pd.DataFrame(\n",
    "        {\n",
    "            \"patientid\": patientid_list,\n",
    "            \"age\": patientage_list,\n",
    "            \"dob\": patient_date_of_birth_list,\n",
    "            \"gender\": patient_gender_list,\n",
    "            \"VentricularRate\": patient_VentricularRate_list,\n",
    "            \"AtrialRate\": patient_AtrialRate_list,\n",
    "            \"PRInterval\": patient_PRInterval_list,\n",
    "            \"QRSDuration\": patient_QRSDuration_list,\n",
    "            \"QTInterval\": patient_QTInterval_list,\n",
    "            \"QTCorrected\": patient_QTCorrected_list,\n",
    "            \"PAxis\": patient_Paxis_list,\n",
    "            \"RAXis\": patient_Raxis_list,\n",
    "            \"TAxis\": patient_TAxis_list,\n",
    "            \"QRSCount\": patient_QRSCount_list,\n",
    "            \"QOnset\": patient_QOnset_list,\n",
    "            \"QOffset\": patient_QOffset_list,\n",
    "            \"POnset\": patient_POnset_list,\n",
    "            \"POffset\": patient_POffset_list,\n",
    "            \"TOffset\": patient_TOffset_list,\n",
    "            \"ECGSampleBase\": patient_ECGSampleBase_list,\n",
    "            \"ECGSampleExponent\": patient_ECGSampleExponent_list,\n",
    "            \"QTcFrederica\": patient_QTcFrederica_list,\n",
    "            \"Location\": patient_Location_list,\n",
    "            \"LocationName\": patient_LocatioName_list,\n",
    "            \"RoomID\": patient_RoomID_list,\n",
    "            \"AcquisitionDate\": patient_acquisitiondate_list,\n",
    "            \"AcquisitionTime\": patient_acquisitiontime_list,\n",
    "            \"Status\": patient_status_list,\n",
    "            \"AcquisitionDevice\": patient_acquisitiondevice_list,\n",
    "            \"ReferringMDLastName\": patient_referringMDLastName_list,\n",
    "            \"AnalysisSoftware\": patient_AnalysisSoftware_list,\n",
    "            \"AcquisitionSoftwareVersion\": patient_acquisitionSoftwareVersion_list,\n",
    "            \"Diagnosis\": diagnosis_list,\n",
    "            \"Original_Diagnosis\": original_diagnosis_list,\n",
    "            \"xml_path\": xml_path_list,\n",
    "            \"ecg_output_path\": ecg_output_path_list,\n",
    "        }\n",
    "    )\n",
    "    return df_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### List all files in '/media/data1/muse_ge/ecg_retrospective' ending in XML and add them to list\n",
    "import glob\n",
    "import os\n",
    "\n",
    "## Get all fins in directory 'media/data1/muse_ge/ecg_retrospective' ending in .XML\n",
    "path = \"/media/data1/muse_ge/ecg_retrospective\"\n",
    "all_files = glob.glob(os.path.join(path, \"*.xml\"))\n",
    "### Create dataframe with all ECG files\n",
    "df = pd.DataFrame(all_files, columns=[\"path\"])\n",
    "display(df)\n",
    "\n",
    "# 1711846 files as of 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/20230313_ECG_path.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_output = generate_ecg_dataframe_and_npy(df)\n",
    "# df_output.to_csv(\"data/20221002_ECG.csv\")\n",
    "# df_output = pd.read_csv(\"data/20221002_ECG_mod_diagnosis.csv\")\n",
    "# display(df_output.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_output['ecg_abnormal'] = np.where(df_output['Diagnosis'].str.contains('ECG anormal'), 1, np.where(df_output['Diagnosis'].str.contains('ECG normal'), 0, -1))\n",
    "# Remove ECG anormal and ECG normal from diagnosis\n",
    "# df_output['Diagnosis'] = df_output['Diagnosis'].str.replace('ECG anormal', '')\n",
    "# df_output['Original_Diagnosis'] = df_output['Original_Diagnosis'].str.replace('ECG normal', '')\n",
    "# df_output['Original_Diagnosis'] = df_output['Diagnosis'].str.replace('ECG anormal', '')\n",
    "# df_output['Diagnosis'] = df_output['Original_Diagnosis'].str.replace('ECG normal', '')\n",
    "# df_output.to_csv('data/20221002_ECG_mod_diagnosis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_output.ecg_abnormal.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = (\n",
    "    df_output.groupby([\"patientid\", \"AcquisitionDate\", \"AcquisitionTime\"])\n",
    "    .first()\n",
    "    .reset_index()\n",
    ")\n",
    "display(df_stats(df_output))\n",
    "display(df_stats(df_m))\n",
    "## The ECGs can be grouped by patient id, date and time to have a 1 unique row per ECG - this means the filename to save the ECG also needs to have the date and time in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir = os.getcwd() + '/ekg_waveforms_output/'\n",
    "# ekg_batch_run(df['path'][0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display top 1000 most frequent df_output['Diagnosis]\n",
    "display(df_output[\"Diagnosis\"].value_counts()[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alexis Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.height', 1000)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"max_colwidth\", 200)\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"R_HOME\"] = \"/root/miniconda3/envs/R/lib/R\"\n",
    "\n",
    "import rpy2.robjects as objects\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "base = importr(\"base\")\n",
    "r_pROC = importr(\"pROC\")\n",
    "base._libPaths()[0]\n",
    "\n",
    "\n",
    "def df_stats(df):\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    print(\"\\n***** Shape: \", df.shape, \" *****\\n\")\n",
    "\n",
    "    columns_list = df.columns.values.tolist()\n",
    "    isnull_list = df.isnull().sum().values.tolist()\n",
    "    isunique_list = df.nunique().values.tolist()\n",
    "    dtypes_list = df.dtypes.tolist()\n",
    "\n",
    "    list_stat_val = list(zip(columns_list, isnull_list, isunique_list, dtypes_list))\n",
    "    df_stat_val = pd.DataFrame(\n",
    "        list_stat_val, columns=[\"Name\", \"Null\", \"Unique\", \"Dtypes\"]\n",
    "    )\n",
    "    print(tabulate(df_stat_val, headers=\"keys\", tablefmt=\"psql\"))\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/20230313_ECG_path.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CLI_xml2df as xml2df\n",
    "\n",
    "df_output = xml2df.tinyxml2df(\n",
    "    df[\"path\"], out_path=\"data/ekg_waveforms_output/\"\n",
    ").read2flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_output.to_csv('data/20230314_ECG_path_with_NPY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_output.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_array = np.load(df_output[\"npy_path\"][0])\n",
    "# Transpose the array to shape=[12, 2500]\n",
    "ecg_transposed = np.transpose(npy_array, (1, 0, 2))\n",
    "ecg_transposed = ecg_transposed.reshape(12, 2500)\n",
    "\n",
    "import ecg_plot\n",
    "\n",
    "ecg_plot.plot(ecg_transposed, sample_rate=250, title=\"ECG 12\")\n",
    "ecg_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot line of ecg_transposed[0] and ecg_transposed[1]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(ecg_transposed[0])\n",
    "plt.plot(ecg_transposed[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagate diagnoses labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ecg = pd.read_parquet(\n",
    "    \"/media/data1/ravram/DeepECG/ekg_waveforms_output/df_xml_2023_03_14_n_1633856.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ecg_sampled = pd.read_csv(\"data/20221002_ECG_mod_diagnosis_sampled_3600.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "def normalize_string(s):\n",
    "    s = unidecode(s)\n",
    "    s = s.strip()\n",
    "    s = re.sub(r\"\\W+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def contains_eligible_diagnosis(normalized_diag, eligible_diagnoses):\n",
    "    for diagnosis in eligible_diagnoses:\n",
    "        if diagnosis in normalized_diag:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def filter_ecg_by_diagnosis(df_ecg, df_ecg_sampled):\n",
    "    df_ecg[\"Normalized_Diag\"] = df_ecg[\"Original_Diag\"].apply(normalize_string)\n",
    "    df_ecg_sampled[\"Normalized_Diagnoses\"] = df_ecg_sampled[\"Original_Diagnosis\"].apply(\n",
    "        normalize_string\n",
    "    )\n",
    "\n",
    "    eligible_diagnoses = set(df_ecg_sampled[\"Normalized_Diagnoses\"])\n",
    "\n",
    "    df_ecg[\"Contains_Eligible_Diagnosis\"] = df_ecg[\"Normalized_Diag\"].apply(\n",
    "        lambda x: contains_eligible_diagnosis(x, eligible_diagnoses)\n",
    "    )\n",
    "    filtered_df = df_ecg[df_ecg[\"Contains_Eligible_Diagnosis\"]]\n",
    "\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = filter_ecg_by_diagnosis(df_ecg, df_ecg_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ecg_sampled[\"Normalized_Diagnoses\"] = df_ecg_sampled[\"Original_Diagnosis\"].apply(\n",
    "    normalize_string\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ecg[\"Normalized_Diag\"] = df_ecg[\"Original_Diag\"].apply(normalize_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some information to help debug the issue\n",
    "eligible_diagnoses = set(df_ecg_sampled[\"Normalized_Diagnoses\"])\n",
    "print(f\"Total number of eligible diagnoses: {len(eligible_diagnoses)}\")\n",
    "print(f\"First 10 eligible diagnoses: {list(eligible_diagnoses)[:10]}\")\n",
    "print(\n",
    "    f\"First 10 normalized diagnoses in df_ecg: {list(df_ecg['Normalized_Diag'].head(10))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = pd.merge(df_ecg_sampled, df_ecg, on=\"xml_path\", how=\"inner\")\n",
    "df_m[\"Contained\"] = df_m.apply(\n",
    "    lambda row: row[\"Normalized_Diagnoses\"] in row[\"Normalized_Diag\"], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ecg[\"Contains_Eligible_Diagnosis\"] = df_ecg[\"Normalized_Diag\"].apply(\n",
    "    lambda x: contains_eligible_diagnosis(x, eligible_diagnoses)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_ecg_sampled[\"Normalized_Diagnoses\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    df_ecg.loc[df_ecg[\"Contains_Eligible_Diagnosis\"] == False][\"Normalized_Diag\"].head(\n",
    "        n=55\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1) Voir quelles données labelbox sont discordantes et me les envoyer pour annotation (et enlever ces ECG de la base de données)\n",
    "### 2) Faire propagation des données labelbox concordantes sur df_ecg (db. parquet)\n",
    "### 3) Dictionnaire pour df_ecg['Contains_Eligible_Diagnosis']==False\n",
    "### 4) Standardiser le dataloader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "92f8e7953dd713aae570801b3fd24ef6d3153646110f5453239c5dc263da578e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
