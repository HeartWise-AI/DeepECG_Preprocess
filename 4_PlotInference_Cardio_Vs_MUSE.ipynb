{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import heartpy as hp\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from random import shuffle\n",
    "from scipy.interpolate import CubicSpline\n",
    "from numba import jit\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.height', 1000)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"max_colwidth\", 200)\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "def df_stats(df):\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    print(\"\\n***** Shape: \", df.shape, \" *****\\n\")\n",
    "\n",
    "    columns_list = df.columns.values.tolist()\n",
    "    isnull_list = df.isnull().sum().values.tolist()\n",
    "    isunique_list = df.nunique().values.tolist()\n",
    "    dtypes_list = df.dtypes.tolist()\n",
    "\n",
    "    list_stat_val = list(zip(columns_list, isnull_list, isunique_list, dtypes_list))\n",
    "    df_stat_val = pd.DataFrame(\n",
    "        list_stat_val, columns=[\"Name\", \"Null\", \"Unique\", \"Dtypes\"]\n",
    "    )\n",
    "    print(tabulate(df_stat_val, headers=\"keys\", tablefmt=\"psql\"))\n",
    "    return df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load predictions and remove columns that are not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "def process_data(data, extend_to_remove_labels=True):\n",
    "    data = data[~data['npy_path'].str.contains('Error')]\n",
    "    data = data[data['npy_path'] != '/media/data1/anolin/temp_new_dataset/ecg_npy/0161727_03-25-2020_10-06-16.npy']\n",
    "    to_remove_labels = ['ST depression (posterior - V7-V8-V9)', 'Tall >2.5 mm', 'J wave', 'Auricular bigeminy', \n",
    "                        'Ventricular bigeminy', 'Sinus Pause', 'Dextrocardia', \n",
    "                        'Hyperacute T wave (lateral, V5-V6)', 'Hyperacute T wave (septal, V1-V2)', \n",
    "                        'Hyperacute T wave (anterior, V3-V4)', 'Bifid', 'RaVL + SV3 > 28 mm (H) or 20 mm (F)', \n",
    "                        'Large >0.08 s', 'Biphasic', 'ST depression et T inversion in V5 or V6']\n",
    "\n",
    "    if (extend_to_remove_labels):\n",
    "        # Extend to_remove_labels to include both suffixes\n",
    "        extended_to_remove_labels = [label + suffix for label in to_remove_labels for suffix in ['_CARDIOLOGIST', '_MUSE']]\n",
    "    else:\n",
    "        extended_to_remove_labels = to_remove_labels\n",
    "\n",
    "    # Drop the extended list of columns from the DataFrame\n",
    "    data = data.drop(columns=extended_to_remove_labels, errors='ignore')\n",
    "    return data\n",
    "\n",
    "df_train = pd.read_parquet('/media/data1/muse_ge/train_trial_v1.1.parquet')\n",
    "df_val = pd.read_parquet('/media/data1/muse_ge/val_trial_v1.1.parquet')\n",
    "df_test = pd.read_parquet('/media/data1/muse_ge/test_trial_v1.1.parquet')\n",
    "\n",
    "# Process data using tqdm loop\n",
    "data_frames = [df_train, df_val, df_test]\n",
    "for i in tqdm(range(len(data_frames))):\n",
    "    data_frames[i] = process_data(data_frames[i])\n",
    "\n",
    "df_train, df_val, df_test = data_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train.diagnosis.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ecg = pd.read_parquet('/media/data1/muse_ge/ECG_ad202207_1453937_cat_labels_MUSE_vs_CARDIOLOGIST_v1.2.parquet')\n",
    "import numpy as np\n",
    "conditions = [\n",
    "    df_ecg['npy_path'].isin(df_train['npy_path']),\n",
    "    df_ecg['npy_path'].isin(df_val['npy_path']),\n",
    "    df_ecg['npy_path'].isin(df_test['npy_path'])\n",
    "]\n",
    "\n",
    "choices = ['train', 'val', 'test']\n",
    "\n",
    "df_ecg['dataset'] = np.select(conditions, choices, default='unknown')\n",
    "df_ecg = process_data(df_ecg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_label_names = ['Sinusal','Regular','Monomorph','QS complex in V1-V2-V3','R complex in V5-V6','T wave inversion (inferior - II, III, aVF)','Left bundle branch block','RaVL > 11 mm','SV1 + RV5 or RV6 > 35 mm','T wave inversion (lateral -I, aVL, V5-V6)','T wave inversion (anterior - V3-V4)','Left axis deviation','Left ventricular hypertrophy','Bradycardia','Q wave (inferior - II, III, aVF)','Afib','Irregularly irregular','Atrial tachycardia (>= 100 BPM)','Nonspecific intraventricular conduction delay','Premature ventricular complex','Polymorph','T wave inversion (septal- V1-V2)','Right bundle branch block','Ventricular paced','ST elevation (anterior - V3-V4)','ST elevation (septal - V1-V2)','1st degree AV block','Premature atrial complex','Atrial flutter',\"rSR' in V1-V2\",'qRS in V5-V6-I, aVL','Left anterior fascicular block','Right axis deviation','2nd degree AV block - mobitz 1','ST depression (inferior - II, III, aVF)','Acute pericarditis','ST elevation (inferior - II, III, aVF)','Low voltage','Regularly irregular','Bifid','Junctional rhythm','Left atrial enlargement','ST elevation (lateral - I, aVL, V5-V6)','Atrial paced','Right ventricular hypertrophy','Delta wave','Wolff-Parkinson-White (Pre-excitation syndrome)','Prolonged QT','ST depression (anterior - V3-V4)','QRS complex negative in III','RaVL + SV3 > 28 mm (H) or 20 mm (F)','Q wave (lateral- I, aVL, V5-V6)','Hyperacute T wave (lateral, V5-V6)','Hyperacute T wave (septal, V1-V2)','Supraventricular tachycardia','ST downslopping','ST depression (lateral - I, avL, V5-V6)','2nd degree AV block - mobitz 2','U wave','ST depression et T inversion in V5 or V6','Large >0.08 s','R/S ratio in V1-V2 >1','RV1 + SV6\\xa0> 11 mm','Left posterior fascicular block','Right atrial enlargement','ST depression (septal- V1-V2)','Q wave (septal- V1-V2)','Q wave (anterior - V3-V4)','Hyperacute T wave (anterior, V3-V4)','ST upslopping','Right superior axis','Auricular bigeminy','Ventricular tachycardia','ST elevation (posterior - V7-V8-V9)','Ectopic atrial rhythm (< 100 BPM)','Lead misplacement','Biphasic','Ventricular bigeminy','J wave','Tall >2.5 mm','Third Degree AV Block','Sinus Pause','Acute MI','Early repolarization','Q wave (posterior - V7-V9)','Bi-atrial enlargement','LV pacing','Dextrocardia','Brugada','Ventricular Rhythm','ST depression (posterior - V7-V8-V9)','no_qrs']\n",
    "labels_to_remove = ['ST depression (posterior - V7-V8-V9)','Tall >2.5 mm', 'J wave', 'Auricular bigeminy', 'Ventricular bigeminy', 'Sinus Pause', 'Dextrocardia', 'Hyperacute T wave (lateral, V5-V6)', 'Hyperacute T wave (septal, V1-V2)', 'Hyperacute T wave (anterior, V3-V4)', 'Bifid', 'RaVL + SV3 > 28 mm (H) or 20 mm (F)', 'Large >0.08 s', 'Biphasic', 'ST depression et T inversion in V5 or V6']\n",
    "\n",
    "# Remove specified labels from y_label_names\n",
    "y_label_names = [label for label in y_label_names if label not in labels_to_remove]\n",
    "print(len(y_label_names))\n",
    "print(y_label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.load('/media/data1/muse_ge/X_test_v1.2.npy').astype(np.float16)\n",
    "Y_val = np.load('/media/data1/muse_ge/Y_test_v1.2.npy').astype(np.float16)\n",
    "\n",
    "og_labels =  ['Sinusal','Regular','Monomorph','QS complex in V1-V2-V3','R complex in V5-V6','T wave inversion (inferior - II, III, aVF)','Left bundle branch block','RaVL > 11 mm','SV1 + RV5 or RV6 > 35 mm','T wave inversion (lateral -I, aVL, V5-V6)','T wave inversion (anterior - V3-V4)','Left axis deviation','Left ventricular hypertrophy','Bradycardia','Q wave (inferior - II, III, aVF)','Afib','Irregularly irregular','Atrial tachycardia (>= 100 BPM)','Nonspecific intraventricular conduction delay','Premature ventricular complex','Polymorph','T wave inversion (septal- V1-V2)','Right bundle branch block','Ventricular paced','ST elevation (anterior - V3-V4)','ST elevation (septal - V1-V2)','1st degree AV block','Premature atrial complex','Atrial flutter',\"rSR' in V1-V2\",'qRS in V5-V6-I, aVL','Left anterior fascicular block','Right axis deviation','2nd degree AV block - mobitz 1','ST depression (inferior - II, III, aVF)','Acute pericarditis','ST elevation (inferior - II, III, aVF)','Low voltage','Regularly irregular','Bifid','Junctional rhythm','Left atrial enlargement','ST elevation (lateral - I, aVL, V5-V6)','Atrial paced','Right ventricular hypertrophy','Delta wave','Wolff-Parkinson-White (Pre-excitation syndrome)','Prolonged QT','ST depression (anterior - V3-V4)','QRS complex negative in III','RaVL + SV3 > 28 mm (H) or 20 mm (F)','Q wave (lateral- I, aVL, V5-V6)','Hyperacute T wave (lateral, V5-V6)','Hyperacute T wave (septal, V1-V2)','Supraventricular tachycardia','ST downslopping','ST depression (lateral - I, avL, V5-V6)','2nd degree AV block - mobitz 2','U wave','ST depression et T inversion in V5 or V6','Large >0.08 s','R/S ratio in V1-V2 >1','RV1 + SV6\\xa0> 11 mm','Left posterior fascicular block','Right atrial enlargement','ST depression (septal- V1-V2)','Q wave (septal- V1-V2)','Q wave (anterior - V3-V4)','Hyperacute T wave (anterior, V3-V4)','ST upslopping','Right superior axis','Auricular bigeminy','Ventricular tachycardia','ST elevation (posterior - V7-V8-V9)','Ectopic atrial rhythm (< 100 BPM)','Lead misplacement','Biphasic','Ventricular bigeminy','J wave','Tall >2.5 mm','Third Degree AV Block','Sinus Pause','Acute MI','Early repolarization','Q wave (posterior - V7-V9)','Bi-atrial enlargement','LV pacing','Dextrocardia','Brugada','Ventricular Rhythm','ST depression (posterior - V7-V8-V9)','no_qrs']\n",
    "to_remove_labels = ['ST depression (posterior - V7-V8-V9)','Tall >2.5 mm', 'J wave', 'Auricular bigeminy', 'Ventricular bigeminy', 'Sinus Pause', 'Dextrocardia', 'Hyperacute T wave (lateral, V5-V6)', 'Hyperacute T wave (septal, V1-V2)', 'Hyperacute T wave (anterior, V3-V4)', 'Bifid', 'RaVL + SV3 > 28 mm (H) or 20 mm (F)', 'Large >0.08 s', 'Biphasic', 'ST depression et T inversion in V5 or V6']\n",
    "\n",
    "pos_to_drop = list()\n",
    "new_label_names = list()\n",
    "for pos, item in enumerate(og_labels):\n",
    "    if item in to_remove_labels:\n",
    "        pos_to_drop.append(pos)\n",
    "    else:\n",
    "        new_label_names.append(item)\n",
    "Y_val = np.delete(Y_val, pos_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_ecg is your DataFrame\n",
    "# Identify columns ending with _CARDIOLOGIST and _MUSE\n",
    "cardiologist_cols = [col for col in df_ecg.columns if col.endswith('_CARDIOLOGIST')]\n",
    "muse_cols = [col for col in df_ecg.columns if col.endswith('_MUSE')]\n",
    "# Create subsets for each\n",
    "df_cardiologist = df_ecg[cardiologist_cols]\n",
    "df_muse = df_ecg[muse_cols]\n",
    "# Keep only columns between Sinusal_CARDIOLOGIST and no_qrs_CARDIOLOGIST\n",
    "start_col = \"Sinusal_CARDIOLOGIST\"\n",
    "end_col = \"no_qrs_CARDIOLOGIST\"\n",
    "\n",
    "df_cardiologist = df_cardiologist.loc[:, start_col:end_col]\n",
    "start_col = \"Sinusal_MUSE\"\n",
    "end_col = \"no_qrs_MUSE\"\n",
    "\n",
    "df_muse = df_muse.loc[:, start_col:end_col]\n",
    "\n",
    "df_cardiologist = df_cardiologist.apply(lambda x: x.apply(lambda y: 1 if y >= 1 else 0))\n",
    "df_muse = df_muse.apply(lambda x: x.apply(lambda y: 1 if y >= 1 else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cardiologist = pd.merge(df_cardiologist, df_ecg[['npy_path', 'dataset', 'validated by MD', 'diagnosis', 'original_diagnosis']], left_index=True, right_index=True)\n",
    "df_muse = pd.merge(df_muse, df_ecg[['npy_path', 'dataset', 'validated by MD', 'diagnosis', 'original_diagnosis']], left_index=True, right_index=True)\n",
    "\n",
    "one_hot_encoded_cardiologist_val = df_cardiologist[df_cardiologist['dataset'] == 'val']\n",
    "one_hot_encoded_muse_val = df_muse[df_muse['dataset'] == 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "\n",
    "sigmoid_v = np.vectorize(sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Y_PRED : TO DO - LOAD FINAL MODEL OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.load('/media/data1/anolin/results_benchmarkv2/resnet50_notscaled_1997_v1.1/output_1.npy')\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "\n",
    "sigmoid_v = np.vectorize(sigmoid)\n",
    "Y_pred = sigmoid_v(Y_pred)\n",
    "#display(Y_pred)\n",
    "sigmoid_v_bin =  np.where(Y_pred > 0.5, 1, 0)\n",
    "#sigmoid_v_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming sigmoid_v_bin, one_hot_encoded_cardiologist_val, and one_hot_encoded_muse_val have aligned indices\n",
    "\n",
    "# Create a dataframe for sigmoid_v_bin with labels\n",
    "df_sigmoid_v_bin = pd.DataFrame(sigmoid_v_bin, columns=new_label_names)\n",
    "\n",
    "# Reset index if necessary and ensure it aligns across all DataFrames\n",
    "df_sigmoid_v_bin.reset_index(drop=True, inplace=True)\n",
    "one_hot_encoded_cardiologist_val.reset_index(drop=True, inplace=True)\n",
    "one_hot_encoded_muse_val.reset_index(drop=True, inplace=True)\n",
    "try:\n",
    "    one_hot_encoded_muse_val = one_hot_encoded_muse_val.drop(['npy_path', 'dataset', 'validated by MD', 'diagnosis', 'original_diagnosis'], axis=1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Merge the dataframes on index\n",
    "df_merged = pd.concat([df_sigmoid_v_bin, one_hot_encoded_cardiologist_val, one_hot_encoded_muse_val], axis=1).reset_index()\n",
    "df_merged.reset_index(inplace=True)\n",
    "condition = (df_merged['validated by MD'] == 1) & (df_merged['diagnosis'] != df_merged['original_diagnosis'])\n",
    "df_modified_by_cardiologist = df_merged.loc[condition]\n",
    "df_validated_by_cardiologist = df_merged.loc[df_merged['validated by MD'] == 1]\n",
    "df_not_validated_by_cardiologist = df_merged.loc[df_merged['validated by MD'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_modified_by_cardiologist.to_csv('data/core_model_performance/df_modified_by_cardiologist.csv')\n",
    "#df_validated_by_cardiologist.to_csv('data/core_model_performance/df_validated_by_cardiologist.csv')\n",
    "#df_not_validated_by_cardiologist.to_csv('data/core_model_performance/df_not_validated_by_cardiologist.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SELECT A DATAFRAME FOR SUBSEQUENT ANALYSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_SELECTED = df_validated_by_cardiologist\n",
    "# Remove unnecessary columns\n",
    "unnecessary_columns = ['Unnamed: 0', 'level_0', 'index']\n",
    "df_SELECTED.drop(columns=unnecessary_columns, inplace=True, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute per 'category' metrics and 'overall' metrics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_micro_macro_statistics\n",
    "\n",
    "import json\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"utils/categories.json\"\n",
    "\n",
    "# Load the JSON file\n",
    "with open(file_path, \"r\") as file:\n",
    "    categories = json.load(file)\n",
    "\n",
    "# Print the loaded categories\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute micro and macro AUC/PR for CARDIOLOGIST\n",
    "micro_ROC_cardiologist, micro_PR_cardiologist, Sensitivity_micro_avg_cardiologist, Specificity_micro_avg_cardiologist = plot_micro_macro_statistics.compute_macro_metrics_all_with_youden(df_SELECTED, '_CARDIOLOGIST')\n",
    "macro_ROC_cardiologist, macro_PR_cardiologist, Sensitivity_macro_avg_cardiologist, Specificity_macro_avg_cardiologist = plot_micro_macro_statistics.compute_macro_metrics_all_with_youden(df_SELECTED, '_CARDIOLOGIST')\n",
    "\n",
    "# Compute micro and macro AUC/PR for MUSE\n",
    "micro_ROC_muse, micro_PR_muse, Sensitivity_micro_avg_muse, Specificity_micro_avg_muse = plot_micro_macro_statistics.compute_micro_metrics_all_with_youden(df_SELECTED, '_MUSE')\n",
    "macro_ROC_muse, macro_PR_muse, Sensitivity_macro_avg_muse, Specificity_macro_avg_muse = plot_micro_macro_statistics.compute_macro_metrics_all_with_youden(df_SELECTED, '_MUSE')\n",
    "# Create a dictionary with metrics\n",
    "metrics = {\n",
    "    'Sensitivity_micro': [Sensitivity_micro_avg_cardiologist, Sensitivity_micro_avg_muse],\n",
    "    'Specificity_micro': [Specificity_micro_avg_cardiologist, Specificity_micro_avg_muse],\n",
    "    'ROC_micro': [micro_ROC_cardiologist, micro_ROC_muse],\n",
    "    'PR_micro': [micro_PR_cardiologist, micro_PR_muse],\n",
    "    'Sensitivity_macro': [Sensitivity_macro_avg_cardiologist, Sensitivity_macro_avg_muse],\n",
    "    'Specificity_macro': [Specificity_macro_avg_cardiologist, Specificity_macro_avg_muse],\n",
    "    'ROC_macro': [macro_ROC_cardiologist, macro_ROC_muse],\n",
    "    'PR_macro': [macro_PR_cardiologist, macro_PR_muse]\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a DataFrame\n",
    "df_simple = pd.DataFrame(metrics, index=['Cardiologist', 'MUSE'])\n",
    "\n",
    "# Display the DataFrame\n",
    "df_simple = df_simple.applymap(lambda x: round(x * 100, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple.to_csv('data/core_model_performance/overall_performance.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute the metrics for the provided categories\n",
    "metrics_results = plot_micro_macro_statistics.compute_metrics_for_categories(df_SELECTED, categories)\n",
    "# Converting the nested dictionary to DataFrame\n",
    "metrics_df = pd.DataFrame.from_dict(metrics_results, orient='index').reset_index()\n",
    "\n",
    "\n",
    "# Flattening the nested dictionaries and ensuring unique column names\n",
    "for column in ['CARDIOLOGIST', 'MUSE']:\n",
    "    flattened = pd.json_normalize(metrics_df[column])\n",
    "    # Adding a prefix to the column names to ensure uniqueness\n",
    "    flattened.columns = [f\"{column}_{subcol}\" for subcol in flattened.columns]\n",
    "    # Dropping the original column to avoid name conflict\n",
    "    metrics_df = metrics_df.drop(columns=[column])\n",
    "    # Joining the flattened DataFrame\n",
    "    metrics_df = metrics_df.join(flattened)\n",
    "    \n",
    "\n",
    "# Display the DataFrame\n",
    "for col in metrics_df.columns:\n",
    "    if metrics_df[col].dtype.kind in 'bifc':  # checks if the column is numerical\n",
    "        metrics_df[col] = metrics_df[col].apply(lambda x: round(x * 100, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(metrics_df)\n",
    "metrics_df.to_csv('data/core_model_performance/categorical_performance.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "# Assuming df_merged is the merged DataFrame containing sigmoid_v_bin, one_hot_encoded_cardiologist_val, and one_hot_encoded_muse_val\n",
    "metrics_results = plot_micro_macro_statistics.compute_individual_metrics(df_SELECTED, new_label_names)\n",
    "\n",
    "# Create an empty DataFrame\n",
    "df_metrics = pd.DataFrame()\n",
    "\n",
    "# Building the DataFrame\n",
    "data = []\n",
    "for label, suffixes in metrics_results.items():\n",
    "    row = {'Label': label}\n",
    "    for suffix, metrics in suffixes.items():\n",
    "        for metric_name, value in metrics.items():\n",
    "            col_name = metric_name + suffix\n",
    "            row[col_name] = value\n",
    "    data.append(row)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df_metrics = pd.DataFrame(data)\n",
    "\n",
    "# Reorder columns to put ROC columns next to each other and PR columns next to each other\n",
    "df_metrics = df_metrics[['Label', 'ROC_CARDIOLOGIST', 'Sensitivity_CARDIOLOGIST', 'Specificity_CARDIOLOGIST', 'PR_CARDIOLOGIST', 'ROC_MUSE',  'Sensitivity_MUSE', 'Specificity_MUSE', 'PR_MUSE']]\n",
    "\n",
    "df_metrics['PR_diff'] = df_metrics['PR_CARDIOLOGIST'] - df_metrics['PR_MUSE']\n",
    "df_metrics['ROC_diff'] = df_metrics['ROC_CARDIOLOGIST'] - df_metrics['ROC_MUSE']\n",
    "df_metrics['Sensitivity_diff'] = df_metrics['Sensitivity_CARDIOLOGIST'] - df_metrics['Sensitivity_MUSE']\n",
    "df_metrics['Specificity_diff'] = df_metrics['Specificity_CARDIOLOGIST'] - df_metrics['Specificity_MUSE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Revised function to group the df_metrics DataFrame by the provided categories\n",
    "def group_metrics_by_categories(df, categories):\n",
    "    \"\"\"\n",
    "    Groups the df_metrics DataFrame by specified categories based on the 'Label' column.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The DataFrame to be grouped (df_metrics).\n",
    "    categories (dict): A dictionary where keys are category names and values are lists of labels belonging to each category.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary of DataFrames, where each key is a category and each value is a DataFrame of rows belonging to that category.\n",
    "    \"\"\"\n",
    "\n",
    "    # Creating a label to category mapping\n",
    "    label_to_category = {label: category for category, labels in categories.items() for label in labels}\n",
    "\n",
    "    # Mapping each row to its category based on the 'Label' column\n",
    "    df['Category'] = df['Label'].map(label_to_category)\n",
    "\n",
    "    # Grouping the DataFrame by the 'Category' column\n",
    "    grouped_data_dict = {category: group for category, group in df.groupby('Category')}\n",
    "\n",
    "    return grouped_data_dict\n",
    "\n",
    "# Applying the revised function to group df_metrics by the provided categories\n",
    "grouped_metrics_data = group_metrics_by_categories(df_metrics, categories)\n",
    "\n",
    "\n",
    "\n",
    "# Sorting this DataFrame by 'Category'\n",
    "sorted_category_label_df = df_metrics.sort_values(by=['Category','ROC_CARDIOLOGIST'], ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "for col in sorted_category_label_df.columns:\n",
    "    if sorted_category_label_df[col].dtype.kind in 'bifc':  # checks if the column is numerical\n",
    "        sorted_category_label_df[col] = sorted_category_label_df[col].apply(lambda x: round(x * 100, 1))\n",
    "\n",
    "sorted_category_label_df.to_csv('data/core_model_performance/individual_performance.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EchoNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/EchoNext/echo_results.per_ecg.csv')\n",
    "display(df.head(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this is to get the label frequency from the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_ = np.load('/media/data1/muse_ge/Y_train_v1.1.npy').astype(np.int64)\n",
    "\n",
    "pos_to_drop = list()\n",
    "new_label_names = list()\n",
    "for pos, item in enumerate(og_labels):\n",
    "    if item in to_remove_labels:\n",
    "        pos_to_drop.append(pos)\n",
    "    else:\n",
    "        new_label_names.append(item)\n",
    "\n",
    "#print(Y_train.shape)\n",
    "Y_val_ = np.delete(Y_val_, pos_to_drop, axis=1)\n",
    "\n",
    "\n",
    "label_counts = np.sum(Y_val_, axis=0)\n",
    "label_counts/Y_val_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the prevalence to the df\n",
    "df_out['Prevalence'] = label_counts/Y_val_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a label for ease of use in matplotlib\n",
    "df_out_ = df_out[['ROC','Prevalence']]\n",
    "df_out_.index = [f'{i} ({\"{:.3f}\".format(j)})' for i,j in zip(df_out_.index,df_out_.ROC)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Robert final approach (seems finicky with figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "figure(figsize=(12, 2), dpi=80)\n",
    "df_out_.sort_values('ROC').plot( kind= 'bar' , secondary_y= 'Prevalence' )\n",
    "plt.xticks(rotation=90, fontsize=8)\n",
    "plt.title('Distribution of ROC avg 3 seed')\n",
    "#plt.savefig('/volume/core_model/ROC.jpg', dpi=600, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General performance histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.histplot(df_out['ROC'])\n",
    "plt.title(\"Score distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first approach without frenquency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, auc, accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "og_labels =  ['Sinusal','Regular','Monomorph','QS complex in V1-V2-V3','R complex in V5-V6','T wave inversion (inferior - II, III, aVF)','Left bundle branch block','RaVL > 11 mm','SV1 + RV5 or RV6 > 35 mm','T wave inversion (lateral -I, aVL, V5-V6)','T wave inversion (anterior - V3-V4)','Left axis deviation','Left ventricular hypertrophy','Bradycardia','Q wave (inferior - II, III, aVF)','Afib','Irregularly irregular','Atrial tachycardia (>= 100 BPM)','Nonspecific intraventricular conduction delay','Premature ventricular complex','Polymorph','T wave inversion (septal- V1-V2)','Right bundle branch block','Ventricular paced','ST elevation (anterior - V3-V4)','ST elevation (septal - V1-V2)','1st degree AV block','Premature atrial complex','Atrial flutter',\"rSR' in V1-V2\",'qRS in V5-V6-I, aVL','Left anterior fascicular block','Right axis deviation','2nd degree AV block - mobitz 1','ST depression (inferior - II, III, aVF)','Acute pericarditis','ST elevation (inferior - II, III, aVF)','Low voltage','Regularly irregular','Bifid','Junctional rhythm','Left atrial enlargement','ST elevation (lateral - I, aVL, V5-V6)','Atrial paced','Right ventricular hypertrophy','Delta wave','Wolff-Parkinson-White (Pre-excitation syndrome)','Prolonged QT','ST depression (anterior - V3-V4)','QRS complex negative in III','RaVL + SV3 > 28 mm (H) or 20 mm (F)','Q wave (lateral- I, aVL, V5-V6)','Hyperacute T wave (lateral, V5-V6)','Hyperacute T wave (septal, V1-V2)','Supraventricular tachycardia','ST downslopping','ST depression (lateral - I, avL, V5-V6)','2nd degree AV block - mobitz 2','U wave','ST depression et T inversion in V5 or V6','Large >0.08 s','R/S ratio in V1-V2 >1','RV1 + SV6\\xa0> 11 mm','Left posterior fascicular block','Right atrial enlargement','ST depression (septal- V1-V2)','Q wave (septal- V1-V2)','Q wave (anterior - V3-V4)','Hyperacute T wave (anterior, V3-V4)','ST upslopping','Right superior axis','Auricular bigeminy','Ventricular tachycardia','ST elevation (posterior - V7-V8-V9)','Ectopic atrial rhythm (< 100 BPM)','Lead misplacement','Biphasic','Ventricular bigeminy','J wave','Tall >2.5 mm','Third Degree AV Block','Sinus Pause','Acute MI','Early repolarization','Q wave (posterior - V7-V9)','Bi-atrial enlargement','LV pacing','Dextrocardia','Brugada','Ventricular Rhythm','ST depression (posterior - V7-V8-V9)','no_qrs']\n",
    "to_remove_labels = ['ST depression (posterior - V7-V8-V9)','Tall >2.5 mm', 'J wave', 'Auricular bigeminy', 'Ventricular bigeminy', 'Sinus Pause', 'Dextrocardia', 'Hyperacute T wave (lateral, V5-V6)', 'Hyperacute T wave (septal, V1-V2)', 'Hyperacute T wave (anterior, V3-V4)', 'Bifid', 'RaVL + SV3 > 28 mm (H) or 20 mm (F)', 'Large >0.08 s', 'Biphasic', 'ST depression et T inversion in V5 or V6']\n",
    "\n",
    "Y_val = np.load('/media/data1/anolin/Y_val_v1.1.npy').astype(np.int64)\n",
    "\n",
    "pos_to_drop = list()\n",
    "new_label_names = list()\n",
    "for pos, item in enumerate(og_labels):\n",
    "    if item in to_remove_labels:\n",
    "        pos_to_drop.append(pos)\n",
    "    else:\n",
    "        new_label_names.append(item)\n",
    "\n",
    "#print(Y_train.shape)\n",
    "Y_val = np.delete(Y_val, pos_to_drop, axis=1)\n",
    "\n",
    "dict_results = dict(zip(new_label_names,[[0,0,0] for _ in range(len(new_label_names))]))\n",
    "for i in [2023,1997,42]:\n",
    "    Y_pred = np.load(f'/media/data1/anolin/results_benchmarkv2/resnet50_notscaled_{i}_v1.1/output_1.npy')\n",
    "    Y_pred = sigmoid_v(Y_pred)\n",
    "    sigmoid_v_bin =  np.where(Y_pred > 0.5, 1, 0)\n",
    "    \n",
    "\n",
    "    for pos, label in enumerate(new_label_names):\n",
    "        try:\n",
    "            ROC = roc_auc_score(Y_val[:,pos], sigmoid_v_bin[:,pos], average=None)\n",
    "        except:\n",
    "            ROC = 0.5\n",
    "        precision, recall, thresholds = precision_recall_curve(Y_val[:,pos], sigmoid_v_bin[:,pos])\n",
    "        PR = auc(recall, precision)\n",
    "\n",
    "        acc = accuracy_score(Y_val[:,pos], sigmoid_v_bin[:,pos])\n",
    "\n",
    "        dict_results[label][0] += ROC\n",
    "        dict_results[label][1] += PR\n",
    "        dict_results[label][2] += acc\n",
    "\n",
    "for k,v in dict_results.items():\n",
    "    v[0] = v[0]/3\n",
    "    v[1] = v[1]/3\n",
    "    v[2] = v[2]/3\n",
    "df_out = pd.DataFrame.from_dict(dict_results).T\n",
    "df_out.columns = ['ROC','PR','ACC']\n",
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(rc={'figure.figsize':(15.7,2)})\n",
    "\n",
    "sns.barplot(y=df_out.sort_values('ACC', ascending=True)['ACC'], x=df_out.sort_values('ACC', ascending=True).index)\n",
    "plt.xticks(rotation=90, fontsize=8)\n",
    "plt.title('Distribution of ACC avg 3 seed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.histplot(df_out['ROC'])\n",
    "plt.title(\"Score distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test the scaling's impace on the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val = np.load('/media/data1/anolin/Y_val_v1.1.npy').astype(np.int64)\n",
    "og_labels =  ['Sinusal','Regular','Monomorph','QS complex in V1-V2-V3','R complex in V5-V6','T wave inversion (inferior - II, III, aVF)','Left bundle branch block','RaVL > 11 mm','SV1 + RV5 or RV6 > 35 mm','T wave inversion (lateral -I, aVL, V5-V6)','T wave inversion (anterior - V3-V4)','Left axis deviation','Left ventricular hypertrophy','Bradycardia','Q wave (inferior - II, III, aVF)','Afib','Irregularly irregular','Atrial tachycardia (>= 100 BPM)','Nonspecific intraventricular conduction delay','Premature ventricular complex','Polymorph','T wave inversion (septal- V1-V2)','Right bundle branch block','Ventricular paced','ST elevation (anterior - V3-V4)','ST elevation (septal - V1-V2)','1st degree AV block','Premature atrial complex','Atrial flutter',\"rSR' in V1-V2\",'qRS in V5-V6-I, aVL','Left anterior fascicular block','Right axis deviation','2nd degree AV block - mobitz 1','ST depression (inferior - II, III, aVF)','Acute pericarditis','ST elevation (inferior - II, III, aVF)','Low voltage','Regularly irregular','Bifid','Junctional rhythm','Left atrial enlargement','ST elevation (lateral - I, aVL, V5-V6)','Atrial paced','Right ventricular hypertrophy','Delta wave','Wolff-Parkinson-White (Pre-excitation syndrome)','Prolonged QT','ST depression (anterior - V3-V4)','QRS complex negative in III','RaVL + SV3 > 28 mm (H) or 20 mm (F)','Q wave (lateral- I, aVL, V5-V6)','Hyperacute T wave (lateral, V5-V6)','Hyperacute T wave (septal, V1-V2)','Supraventricular tachycardia','ST downslopping','ST depression (lateral - I, avL, V5-V6)','2nd degree AV block - mobitz 2','U wave','ST depression et T inversion in V5 or V6','Large >0.08 s','R/S ratio in V1-V2 >1','RV1 + SV6\\xa0> 11 mm','Left posterior fascicular block','Right atrial enlargement','ST depression (septal- V1-V2)','Q wave (septal- V1-V2)','Q wave (anterior - V3-V4)','Hyperacute T wave (anterior, V3-V4)','ST upslopping','Right superior axis','Auricular bigeminy','Ventricular tachycardia','ST elevation (posterior - V7-V8-V9)','Ectopic atrial rhythm (< 100 BPM)','Lead misplacement','Biphasic','Ventricular bigeminy','J wave','Tall >2.5 mm','Third Degree AV Block','Sinus Pause','Acute MI','Early repolarization','Q wave (posterior - V7-V9)','Bi-atrial enlargement','LV pacing','Dextrocardia','Brugada','Ventricular Rhythm','ST depression (posterior - V7-V8-V9)','no_qrs']\n",
    "to_remove_labels = ['ST depression (posterior - V7-V8-V9)','Tall >2.5 mm', 'J wave', 'Auricular bigeminy', 'Ventricular bigeminy', 'Sinus Pause', 'Dextrocardia', 'Hyperacute T wave (lateral, V5-V6)', 'Hyperacute T wave (septal, V1-V2)', 'Hyperacute T wave (anterior, V3-V4)', 'Bifid', 'RaVL + SV3 > 28 mm (H) or 20 mm (F)', 'Large >0.08 s', 'Biphasic', 'ST depression et T inversion in V5 or V6']\n",
    "\n",
    "Y_val = np.load('/media/data1/anolin/Y_val_v1.1.npy').astype(np.int64)\n",
    "\n",
    "pos_to_drop = list()\n",
    "new_label_names = list()\n",
    "for pos, item in enumerate(og_labels):\n",
    "    if item in to_remove_labels:\n",
    "        pos_to_drop.append(pos)\n",
    "    else:\n",
    "        new_label_names.append(item)\n",
    "Y_val = np.delete(Y_val, pos_to_drop, axis=1)\n",
    "Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.load('/media/data1/anolin/results_benchmarkv2/resnet50_robustscaler_leads_1997_v1.1/output_1.npy')\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + math.exp(-x))\n",
    "\n",
    "sigmoid_v = np.vectorize(sigmoid)\n",
    "Y_pred = sigmoid_v(Y_pred)\n",
    "sigmoid_v_bin =  np.where(Y_pred > 0.5, 1, 0)\n",
    "sigmoid_v_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scikit_posthocs as sp\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_score(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    numerator = (y_true & y_pred).sum(axis=1)\n",
    "    denominator = (y_true | y_pred).sum(axis=1)\n",
    "\n",
    "    return np.divide(numerator, denominator, out=np.ones_like(numerator, dtype=np.float_),\n",
    "                        where=denominator != 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_condition = list()\n",
    "list_inter = list()\n",
    "list_score = list()\n",
    "\n",
    "metric = 'avg_acc' #['cat_accuracy', 'hamming', 'avg_acc', 'roc_macro', 'roc_micro', 'pr_macro', 'pr_micro']\n",
    "\n",
    "Y_val = np.load('/media/data1/anolin/Y_val_v1.1.npy').astype(np.int64)\n",
    "og_labels =  ['Sinusal','Regular','Monomorph','QS complex in V1-V2-V3','R complex in V5-V6','T wave inversion (inferior - II, III, aVF)','Left bundle branch block','RaVL > 11 mm','SV1 + RV5 or RV6 > 35 mm','T wave inversion (lateral -I, aVL, V5-V6)','T wave inversion (anterior - V3-V4)','Left axis deviation','Left ventricular hypertrophy','Bradycardia','Q wave (inferior - II, III, aVF)','Afib','Irregularly irregular','Atrial tachycardia (>= 100 BPM)','Nonspecific intraventricular conduction delay','Premature ventricular complex','Polymorph','T wave inversion (septal- V1-V2)','Right bundle branch block','Ventricular paced','ST elevation (anterior - V3-V4)','ST elevation (septal - V1-V2)','1st degree AV block','Premature atrial complex','Atrial flutter',\"rSR' in V1-V2\",'qRS in V5-V6-I, aVL','Left anterior fascicular block','Right axis deviation','2nd degree AV block - mobitz 1','ST depression (inferior - II, III, aVF)','Acute pericarditis','ST elevation (inferior - II, III, aVF)','Low voltage','Regularly irregular','Bifid','Junctional rhythm','Left atrial enlargement','ST elevation (lateral - I, aVL, V5-V6)','Atrial paced','Right ventricular hypertrophy','Delta wave','Wolff-Parkinson-White (Pre-excitation syndrome)','Prolonged QT','ST depression (anterior - V3-V4)','QRS complex negative in III','RaVL + SV3 > 28 mm (H) or 20 mm (F)','Q wave (lateral- I, aVL, V5-V6)','Hyperacute T wave (lateral, V5-V6)','Hyperacute T wave (septal, V1-V2)','Supraventricular tachycardia','ST downslopping','ST depression (lateral - I, avL, V5-V6)','2nd degree AV block - mobitz 2','U wave','ST depression et T inversion in V5 or V6','Large >0.08 s','R/S ratio in V1-V2 >1','RV1 + SV6\\xa0> 11 mm','Left posterior fascicular block','Right atrial enlargement','ST depression (septal- V1-V2)','Q wave (septal- V1-V2)','Q wave (anterior - V3-V4)','Hyperacute T wave (anterior, V3-V4)','ST upslopping','Right superior axis','Auricular bigeminy','Ventricular tachycardia','ST elevation (posterior - V7-V8-V9)','Ectopic atrial rhythm (< 100 BPM)','Lead misplacement','Biphasic','Ventricular bigeminy','J wave','Tall >2.5 mm','Third Degree AV Block','Sinus Pause','Acute MI','Early repolarization','Q wave (posterior - V7-V9)','Bi-atrial enlargement','LV pacing','Dextrocardia','Brugada','Ventricular Rhythm','ST depression (posterior - V7-V8-V9)','no_qrs']\n",
    "to_remove_labels = ['ST depression (posterior - V7-V8-V9)','Tall >2.5 mm', 'J wave', 'Auricular bigeminy', 'Ventricular bigeminy', 'Sinus Pause', 'Dextrocardia', 'Hyperacute T wave (lateral, V5-V6)', 'Hyperacute T wave (septal, V1-V2)', 'Hyperacute T wave (anterior, V3-V4)', 'Bifid', 'RaVL + SV3 > 28 mm (H) or 20 mm (F)', 'Large >0.08 s', 'Biphasic', 'ST depression et T inversion in V5 or V6']\n",
    "\n",
    "Y_val = np.load('/media/data1/anolin/Y_val_v1.1.npy').astype(np.int64)\n",
    "\n",
    "pos_to_drop = list()\n",
    "new_label_names = list()\n",
    "for pos, item in enumerate(og_labels):\n",
    "    if item in to_remove_labels:\n",
    "        pos_to_drop.append(pos)\n",
    "    else:\n",
    "        new_label_names.append(item)\n",
    "Y_val = np.delete(Y_val, pos_to_drop, axis=1)\n",
    "\n",
    "dict_eq = {42:0,1997:1,2023:2}\n",
    "\n",
    "for condition in ['notscaled','standardscaler','minmaxscaler','maxabsscaler','robustscaler','quantiletransformeruniform','quantiletransformernormal']:\n",
    "    for approach in [None,'leads']:\n",
    "        if approach == 'leads' and condition == 'notscaled':\n",
    "            continue\n",
    "        for seed in [42,1997,2023]:\n",
    "            if approach == None:\n",
    "                output_matrix = np.load(f'/media/data1/anolin/results_benchmarkv2/resnet50_{condition}_{seed}_v1.1/output_1.npy')\n",
    "            else:\n",
    "                if condition != 'notscaled':\n",
    "                    output_matrix = np.load(f'/media/data1/anolin/results_benchmarkv2/resnet50_{condition}_leads_{seed}_v1.1/output_1.npy')\n",
    "\n",
    "            def sigmoid(x):\n",
    "                return 1 / (1 + math.exp(-x))\n",
    "\n",
    "            sigmoid_v = np.vectorize(sigmoid)\n",
    "            Y_pred = sigmoid_v(output_matrix)\n",
    "            sigmoid_v_bin =  np.where(Y_pred > 0.5, 1, 0)\n",
    "            sigmoid_v_bin\n",
    "\n",
    "\n",
    "            if approach != None:\n",
    "                name = f'{condition}_{approach}'\n",
    "\n",
    "            else:\n",
    "                name = condition\n",
    "\n",
    "            if metric == 'cat_accuracy':\n",
    "                list_condition.append(name)\n",
    "                list_inter.append(dict_eq[seed])\n",
    "                list_score.append(accuracy_score(Y_val, sigmoid_v_bin))\n",
    "\n",
    "            if metric == 'hamming':\n",
    "                list_condition.append(name)\n",
    "                list_inter.append(dict_eq[seed])\n",
    "                list_score.append(accuracy_score(Y_val, sigmoid_v_bin))\n",
    "            \n",
    "            if metric == 'avg_acc':\n",
    "                list_condition.append(name)\n",
    "                list_inter.append(dict_eq[seed])\n",
    "                list_score.append(mean([accuracy_score(Y_val[:,i], sigmoid_v_bin[:,i]) for i in range(Y_val.shape[1])]))\n",
    "\n",
    "            if metric == 'roc_macro':\n",
    "                list_condition.append(name)\n",
    "                list_inter.append(dict_eq[seed])\n",
    "                list_score.append(roc_auc_score(Y_val, sigmoid_v_bin, average='macro'))            \n",
    "                                  \n",
    "            if metric == 'roc_micro':\n",
    "                list_condition.append(name)\n",
    "                list_inter.append(dict_eq[seed])\n",
    "                list_score.append(roc_auc_score(Y_val, sigmoid_v_bin, average='micro'))          \n",
    "\n",
    "\n",
    "            if metric == 'pr_macro':\n",
    "                list_condition.append(name)\n",
    "                list_inter.append(dict_eq[seed])\n",
    "                list_score.append(average_precision_score(Y_val, sigmoid_v_bin, average='macro'))          \n",
    "\n",
    "            if metric == 'pr_micro':\n",
    "                list_condition.append(name)\n",
    "                list_inter.append(dict_eq[seed])\n",
    "                list_score.append(average_precision_score(Y_val, sigmoid_v_bin, average='micro'))     \n",
    "\n",
    "\n",
    "df_ = pd.DataFrame(zip(list_condition,list_inter,list_score), columns=['method','fold','score'])\n",
    "avg_rank = df_.groupby('fold').score.rank(pct=True).groupby(df_.method).mean()\n",
    "test_results = sp.posthoc_conover_friedman(\n",
    "    df_,\n",
    "    melted=True,\n",
    "    block_col='fold',\n",
    "    group_col='method',\n",
    "    y_col='score',\n",
    ")\n",
    "#sp.sign_plot(test_results)\n",
    "#plt.title(\"Conover test PR Macro\")\n",
    "sp.critical_difference_diagram(avg_rank, test_results)\n",
    "plt.title(\"CDD for Acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# effect of filter filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tqdm import tqdm\n",
    "import heartpy as hp\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the resutls\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "list_condition = list()\n",
    "list_inter = list()\n",
    "list_score = list()\n",
    "\n",
    "metric = 'pr_micro' #['cat_accuracy', 'hamming', 'avg_acc', 'roc_macro', 'roc_micro', 'pr_macro', 'pr_micro']\n",
    "\n",
    "Y_val = np.load('/media/data1/anolin/Y_val_v1.1.npy').astype(np.int64)\n",
    "og_labels =  ['Sinusal','Regular','Monomorph','QS complex in V1-V2-V3','R complex in V5-V6','T wave inversion (inferior - II, III, aVF)','Left bundle branch block','RaVL > 11 mm','SV1 + RV5 or RV6 > 35 mm','T wave inversion (lateral -I, aVL, V5-V6)','T wave inversion (anterior - V3-V4)','Left axis deviation','Left ventricular hypertrophy','Bradycardia','Q wave (inferior - II, III, aVF)','Afib','Irregularly irregular','Atrial tachycardia (>= 100 BPM)','Nonspecific intraventricular conduction delay','Premature ventricular complex','Polymorph','T wave inversion (septal- V1-V2)','Right bundle branch block','Ventricular paced','ST elevation (anterior - V3-V4)','ST elevation (septal - V1-V2)','1st degree AV block','Premature atrial complex','Atrial flutter',\"rSR' in V1-V2\",'qRS in V5-V6-I, aVL','Left anterior fascicular block','Right axis deviation','2nd degree AV block - mobitz 1','ST depression (inferior - II, III, aVF)','Acute pericarditis','ST elevation (inferior - II, III, aVF)','Low voltage','Regularly irregular','Bifid','Junctional rhythm','Left atrial enlargement','ST elevation (lateral - I, aVL, V5-V6)','Atrial paced','Right ventricular hypertrophy','Delta wave','Wolff-Parkinson-White (Pre-excitation syndrome)','Prolonged QT','ST depression (anterior - V3-V4)','QRS complex negative in III','RaVL + SV3 > 28 mm (H) or 20 mm (F)','Q wave (lateral- I, aVL, V5-V6)','Hyperacute T wave (lateral, V5-V6)','Hyperacute T wave (septal, V1-V2)','Supraventricular tachycardia','ST downslopping','ST depression (lateral - I, avL, V5-V6)','2nd degree AV block - mobitz 2','U wave','ST depression et T inversion in V5 or V6','Large >0.08 s','R/S ratio in V1-V2 >1','RV1 + SV6\\xa0> 11 mm','Left posterior fascicular block','Right atrial enlargement','ST depression (septal- V1-V2)','Q wave (septal- V1-V2)','Q wave (anterior - V3-V4)','Hyperacute T wave (anterior, V3-V4)','ST upslopping','Right superior axis','Auricular bigeminy','Ventricular tachycardia','ST elevation (posterior - V7-V8-V9)','Ectopic atrial rhythm (< 100 BPM)','Lead misplacement','Biphasic','Ventricular bigeminy','J wave','Tall >2.5 mm','Third Degree AV Block','Sinus Pause','Acute MI','Early repolarization','Q wave (posterior - V7-V9)','Bi-atrial enlargement','LV pacing','Dextrocardia','Brugada','Ventricular Rhythm','ST depression (posterior - V7-V8-V9)','no_qrs']\n",
    "to_remove_labels = ['ST depression (posterior - V7-V8-V9)','Tall >2.5 mm', 'J wave', 'Auricular bigeminy', 'Ventricular bigeminy', 'Sinus Pause', 'Dextrocardia', 'Hyperacute T wave (lateral, V5-V6)', 'Hyperacute T wave (septal, V1-V2)', 'Hyperacute T wave (anterior, V3-V4)', 'Bifid', 'RaVL + SV3 > 28 mm (H) or 20 mm (F)', 'Large >0.08 s', 'Biphasic', 'ST depression et T inversion in V5 or V6']\n",
    "\n",
    "Y_val = np.load('/media/data1/anolin/Y_val_v1.1.npy').astype(np.int64)\n",
    "\n",
    "pos_to_drop = list()\n",
    "new_label_names = list()\n",
    "for pos, item in enumerate(og_labels):\n",
    "    if item in to_remove_labels:\n",
    "        pos_to_drop.append(pos)\n",
    "    else:\n",
    "        new_label_names.append(item)\n",
    "Y_val = np.delete(Y_val, pos_to_drop, axis=1)\n",
    "\n",
    "dict_eq = {42:0,1997:1,2023:2}\n",
    "\n",
    "for low_cut in [1, 0.1, 0.01, -1]: \n",
    "    for high_cut in [100, 75, 50, -1]:\n",
    "        if low_cut == high_cut == -1:\n",
    "            continue\n",
    "\n",
    "        for seed in [42, 1997, 2023]:\n",
    "\n",
    "            output_matrix = np.load(f\"/media/data1/anolin/results_benchmarkv2/resnet50_filtered_{low_cut}_{high_cut}_{seed}_v1.1/output_1.npy\")\n",
    "\n",
    "\n",
    "            sigmoid_v = np.vectorize(sigmoid)\n",
    "            Y_pred = sigmoid_v(output_matrix)\n",
    "            sigmoid_v_bin =  np.where(Y_pred > 0.5, 1, 0)\n",
    "            sigmoid_v_bin\n",
    "\n",
    "            if low_cut != -1 and high_cut != -1:\n",
    "                name_condition = f'BP_{low_cut}_{high_cut}Hz'\n",
    "\n",
    "            elif low_cut == -1 and high_cut != -1:\n",
    "                name_condition = f'LP_{high_cut}Hz'\n",
    "\n",
    "            elif low_cut != -1 and high_cut == -1:\n",
    "                name_condition = f'HP_{low_cut}Hz'\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "            if metric == 'cat_accuracy':\n",
    "                list_condition.append(name_condition)\n",
    "                list_inter.append(dict_eq[seed])\n",
    "                list_score.append(accuracy_score(Y_val, sigmoid_v_bin))\n",
    "\n",
    "            if metric == 'hamming':\n",
    "                list_condition.append(name_condition)\n",
    "                list_inter.append(dict_eq[seed])\n",
    "                list_score.append(accuracy_score(Y_val, sigmoid_v_bin))\n",
    "            \n",
    "            if metric == 'avg_acc':\n",
    "                list_condition.append(name_condition)\n",
    "                list_inter.append(dict_eq[seed])\n",
    "                list_score.append(mean([accuracy_score(Y_val[:,i], sigmoid_v_bin[:,i]) for i in range(Y_val.shape[1])]))\n",
    "\n",
    "            if metric == 'roc_macro':\n",
    "                list_condition.append(name_condition)\n",
    "                list_inter.append(dict_eq[seed])\n",
    "                list_score.append(roc_auc_score(Y_val, sigmoid_v_bin, average='macro'))            \n",
    "                                    \n",
    "            if metric == 'roc_micro':\n",
    "                list_condition.append(name_condition)\n",
    "                list_inter.append(dict_eq[seed])\n",
    "                list_score.append(roc_auc_score(Y_val, sigmoid_v_bin, average='micro'))          \n",
    "\n",
    "\n",
    "            if metric == 'pr_macro':\n",
    "                list_condition.append(name_condition)\n",
    "                list_inter.append(dict_eq[seed])\n",
    "                list_score.append(average_precision_score(Y_val, sigmoid_v_bin, average='macro'))          \n",
    "\n",
    "            if metric == 'pr_micro':\n",
    "                list_condition.append(name_condition)\n",
    "                list_inter.append(dict_eq[seed])\n",
    "                list_score.append(average_precision_score(Y_val, sigmoid_v_bin, average='micro'))     \n",
    "    \n",
    "df_ = pd.DataFrame(zip(list_condition,list_inter,list_score), columns=['method','fold','score'])\n",
    "df_ = pd.concat([df_, df_first[df_first.method == 'notscaled']])\n",
    "avg_rank = df_.groupby('fold').score.rank(pct=True).groupby(df_.method).mean()\n",
    "test_results = sp.posthoc_conover_friedman(\n",
    "    df_,\n",
    "    melted=True,\n",
    "    block_col='fold',\n",
    "    group_col='method',\n",
    "    y_col='score',\n",
    ")\n",
    "#sp.sign_plot(test_results)\n",
    "#plt.title(\"Conover test PR Macro\")\n",
    "sp.critical_difference_diagram(avg_rank, test_results)\n",
    "plt.title(\"CDD for PR Micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rank = df_.groupby('fold').score.rank(pct=True).groupby(df_.method).mean()\n",
    "test_results = sp.posthoc_conover_friedman(\n",
    "    df_,\n",
    "    melted=True,\n",
    "    block_col='fold',\n",
    "    group_col='method',\n",
    "    y_col='score',\n",
    ")\n",
    "#sp.sign_plot(test_results)\n",
    "#plt.title(\"Conover test PR Macro\")\n",
    "sp.critical_difference_diagram(avg_rank, test_results)\n",
    "plt.title(\"CDD for Acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate the datasets\n",
    "list_condition = list()\n",
    "list_inter = list()\n",
    "list_score = list()\n",
    "\n",
    "\n",
    "\n",
    "for file in tqdm(['X_val'], desc='levels'):\n",
    "\n",
    "    X_val = np.load(f'/media/data1/anolin/{file}_v1.1.npy').astype(np.float16)\n",
    "\n",
    "    for low_cut in [1, 0.1, 0.01, -1]: \n",
    "        for high_cut in [100, 75, 50, -1]:\n",
    "\n",
    "            print(f'low_cut: {low_cut}Hz')\n",
    "            print(f'high_cut: {high_cut}Hz')\n",
    "\n",
    "            if low_cut == -1 and high_cut == -1:\n",
    "                continue\n",
    "\n",
    "            # Bandpass filter parameters\n",
    "            lowcut = low_cut  # Define your own lowcut frequency\n",
    "            highcut = high_cut  # Define your own highcut frequency\n",
    "            fs = 250  # Sampling frequency\n",
    "            order = 2  # Filter order\n",
    "            N = X_val.shape[0] # Replace with your actual N\n",
    "\n",
    "            # Create bandpass filter coefficients\n",
    "            if lowcut == -1:\n",
    "                b, a = butter(order, highcut, btype='low', fs=fs)\n",
    "\n",
    "            elif highcut == -1:\n",
    "                b, a = butter(order, lowcut, btype='high', fs=fs)\n",
    "\n",
    "            else:\n",
    "                b, a = butter(order, [lowcut,highcut], btype='bandpass', fs=fs)\n",
    "\n",
    "            def apply_filter(data_slice):\n",
    "                \"\"\"Applies the bandpass filter to a slice of the data.\"\"\"\n",
    "                filtered_slice = np.empty_like(data_slice).astype(np.float16)\n",
    "                for i in range(data_slice.shape[0]):\n",
    "                    for j in range(data_slice.shape[-1]):\n",
    "                        filtered_slice[i, :, j] = filtfilt(b, a, data_slice[i, :, j])\n",
    "                return filtered_slice\n",
    "\n",
    "            # Divide data into chunks for parallel processing\n",
    "            num_processes = cpu_count()\n",
    "            chunk_size = N // num_processes\n",
    "            chunks = [X_val[i:i + chunk_size].astype(np.float16) for i in range(0, N, chunk_size)]\n",
    "\n",
    "            # Perform parallel processing with progress tracking\n",
    "            with Pool(num_processes) as pool:\n",
    "                results = list(tqdm(pool.imap(apply_filter, chunks), total=len(chunks)))\n",
    "\n",
    "            # Reassemble the results\n",
    "            filtered_data = np.concatenate(results, axis=0).astype(np.float16)\n",
    "\n",
    "            np.save(f'/media/data1/anolin/{file}_filtered_{low_cut}_{high_cut}_v1.1.npy', filtered_data.astype(np.float16))\n",
    "            gc.collect()\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "# Bandpass filter parameters\n",
    "lowcut = 0.01  # Define your own lowcut frequency\n",
    "highcut = 100  # Define your own highcut frequency\n",
    "fs = 250  # Sampling frequency\n",
    "order = 2  # Filter order\n",
    "N = X_val.shape[0] # Replace with your actual N\n",
    "\n",
    "# Create bandpass filter coefficients\n",
    "b, a = butter(order, lowcut, btype='highpass', fs=fs)\n",
    "\n",
    "def apply_filter(data_slice):\n",
    "    \"\"\"Applies the bandpass filter to a slice of the data.\"\"\"\n",
    "    filtered_slice = np.empty_like(data_slice).astype(np.float16)\n",
    "    for i in range(data_slice.shape[0]):\n",
    "        for j in range(data_slice.shape[-1]):\n",
    "            filtered_slice[i, :, j] = filtfilt(b, a, data_slice[i, :, j])\n",
    "    return filtered_slice\n",
    "\n",
    "# Divide data into chunks for parallel processing\n",
    "num_processes = cpu_count()\n",
    "chunk_size = N // num_processes\n",
    "chunks = [X_val[i:i + chunk_size].astype(np.float16) for i in range(0, N, chunk_size)]\n",
    "\n",
    "# Perform parallel processing with progress tracking\n",
    "with Pool(num_processes) as pool:\n",
    "    results = list(tqdm(pool.imap(apply_filter, chunks), total=len(chunks)))\n",
    "\n",
    "# Reassemble the results\n",
    "filtered_data = np.concatenate(results, axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
