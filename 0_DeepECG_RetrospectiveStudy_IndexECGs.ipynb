{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.height', 1000)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"max_colwidth\", 200)\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "def df_stats(df):\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    print(\"\\n***** Shape: \", df.shape, \" *****\\n\")\n",
    "\n",
    "    columns_list = df.columns.values.tolist()\n",
    "    isnull_list = df.isnull().sum().values.tolist()\n",
    "    isunique_list = df.nunique().values.tolist()\n",
    "    dtypes_list = df.dtypes.tolist()\n",
    "\n",
    "    list_stat_val = list(zip(columns_list, isnull_list, isunique_list, dtypes_list))\n",
    "    df_stat_val = pd.DataFrame(\n",
    "        list_stat_val, columns=[\"Name\", \"Null\", \"Unique\", \"Dtypes\"]\n",
    "    )\n",
    "    print(tabulate(df_stat_val, headers=\"keys\", tablefmt=\"psql\"))\n",
    "    return df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all XML Files in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.height', 1000)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"max_colwidth\", 200)\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "def df_stats(df):\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    print(\"\\n***** Shape: \", df.shape, \" *****\\n\")\n",
    "\n",
    "    columns_list = df.columns.values.tolist()\n",
    "    isnull_list = df.isnull().sum().values.tolist()\n",
    "    isunique_list = df.nunique().values.tolist()\n",
    "    dtypes_list = df.dtypes.tolist()\n",
    "\n",
    "    list_stat_val = list(zip(columns_list, isnull_list, isunique_list, dtypes_list))\n",
    "    df_stat_val = pd.DataFrame(\n",
    "        list_stat_val, columns=[\"Name\", \"Null\", \"Unique\", \"Dtypes\"]\n",
    "    )\n",
    "    print(tabulate(df_stat_val, headers=\"keys\", tablefmt=\"psql\"))\n",
    "    return df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all XML Files in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "path = \"/media/data1/muse_ge/ecg_retrospective\"\n",
    "all_files = glob.glob(os.path.join(path, \"*.xml\"))\n",
    "\n",
    "# Convert all_files to a DataFrame with a progress bar\n",
    "df = pd.DataFrame(tqdm(all_files, desc='Creating DataFrame'), columns=[\"path\"])\n",
    "display(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the 2 million ECGs into a PARQUET file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv('/media/data1/anolin/added_label_box_2M.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop df_2['RestingECG_PatientDemographics_PatientID'] that are not integers\n",
    "df_2 = df_2[df_2['RestingECG_PatientDemographics_PatientID'].astype(str).str.isnumeric()]\n",
    "### This line converts the 'RestingECG_PatientDemographics_PatientID' column to string type, then uses the str.isnumeric() function to filter out any rows where 'RestingECG_PatientDemographics_PatientID' is not numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_grouped = df_2.groupby(['RestingECG_PatientDemographics_PatientID','RestingECG_TestDemographics_AcquisitionDate','RestingECG_TestDemographics_AcquisitionTime']).first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# Assuming df is your DataFrame and 'path' is the column containing file paths\n",
    "df_2_grouped['path_components'] = df_2_grouped['xml_path'].apply(lambda x: os.path.dirname(x))\n",
    "\n",
    "# if df_2_grouped.path_components is nil add \"data1/anolin/out_ECG_latest/xml\"\n",
    "df_2_grouped.loc[df_2_grouped.path_components == \"\", 'path_components'] = \"/media/data1/muse_ge/ecg_retrospective\"\n",
    "\n",
    "## Get npy_path filename for df_2\n",
    "df_2_grouped['xml_filename'] = df_2_grouped['xml_path'].apply(lambda x: os.path.basename(x))\n",
    "df_2_grouped['xml_path'] = df_2_grouped['path_components'] + \"/\" + df_2_grouped['xml_filename']\n",
    "\n",
    "## Create new dataframe called df3 if df_2_grouped.path_components is equal to /media/data1/anolin/out_ECG_latest/xml\n",
    "df_2_grouped['path_components'] = df_2_grouped['xml_path'].apply(lambda x: os.path.dirname(x))\n",
    "display(df_2_grouped['path_components'].value_counts())\n",
    "################\n",
    "### NPY ########\n",
    "###############\n",
    "\n",
    "## Get npy_path filename for df_2\n",
    "df_2_grouped['npy_filename'] = df_2_grouped['npy_path'].apply(lambda x: os.path.basename(x))\n",
    "\n",
    "## Create new dataframe called df3 if df_2_grouped.path_components is equal to /media/data1/anolin/out_ECG_latest/xml\n",
    "df_2_grouped['new_npy_path'] = '/media/data1/ravram/DeepECG/ekg_waveforms_output/ecg_npy/' + df_2_grouped['npy_filename']\n",
    "df_2_grouped['npy_path'] = df_2_grouped['new_npy_path']\n",
    "## drop new_npy_path\n",
    "df_2_grouped = df_2_grouped.drop(['new_npy_path'], axis=1)\n",
    "\n",
    "## Create new dataframe called df3 if df_2_grouped.path_components is equal to /media/data1/anolin/out_ECG_latest/xml\n",
    "df_2_grouped['npy_path_components'] = df_2_grouped['npy_path'].apply(lambda x: os.path.dirname(x))\n",
    "display(df_2_grouped['npy_path_components'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop npy_path_components and path_components\n",
    "df_2_grouped = df_2_grouped.drop(['npy_path_components','path_components'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_grouped['RestingECG_PatientDemographics_PatientID_int'] = df_2_grouped['RestingECG_PatientDemographics_PatientID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming df_2_grouped is your DataFrame and 'new_xml_path' is the column containing file paths\n",
    "\n",
    "for file_path in tqdm(df_2_grouped['xml_path']):\n",
    "    if os.path.exists(file_path):\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"The file {file_path} does not exist.\")\n",
    "        break\n",
    "df_2_grouped['file_exists'] = df_2_grouped['xml_path'].apply(os.path.exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_2_grouped.RestingECG_PatientDemographics_PatientID.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean the data\n",
    "\n",
    "\n",
    "df_2_grouped['Normalized_Diagnosis_LABELBOX'] = df_2_grouped['Normalized_Diagnosis_LABELBOX'].astype(str)\n",
    "#df_2_grouped = df_2_grouped.drop(['RestingECG_PatientDemographics_PatientFirstName'], axis=1)\n",
    "#df_2_grouped = df_2_grouped.drop(['RestingECG_PatientDemographics_PatientLastName'], axis=1)\n",
    "\n",
    "df_2_grouped['RestingECG_PatientDemographics_PatientID'] = df_2_grouped['RestingECG_PatientDemographics_PatientID'].astype(str)\n",
    "df_2_grouped['RestingECG_TestDemographics_AnalysisSoftwareVersion'] = df_2_grouped['RestingECG_TestDemographics_AnalysisSoftwareVersion'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the column to string type\n",
    "df_2_grouped['RestingECG_TestDemographics_AnalysisSoftwareVersion'] = df_2_grouped['RestingECG_TestDemographics_AnalysisSoftwareVersion'].astype(str)\n",
    "\n",
    "# Replace all non-digit characters with an empty string\n",
    "df_2_grouped['RestingECG_TestDemographics_AnalysisSoftwareVersion'] = df_2_grouped['RestingECG_TestDemographics_AnalysisSoftwareVersion'].str.replace(r'\\D', '', regex=True)\n",
    "# Convert empty strings to NaN\n",
    "df_2_grouped.loc[df_2_grouped['RestingECG_TestDemographics_AnalysisSoftwareVersion'] == '', 'RestingECG_TestDemographics_AnalysisSoftwareVersion'] = np.nan\n",
    "\n",
    "df_2_grouped['RestingECG_TestDemographics_AnalysisSoftwareVersion'] = df_2_grouped['RestingECG_TestDemographics_AnalysisSoftwareVersion'].astype(float).astype('Int64')\n",
    "display(df_2_grouped['RestingECG_TestDemographics_AnalysisSoftwareVersion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_grouped['RestingECG_Order_ExtraADTData1'] = df_2_grouped['RestingECG_Order_ExtraADTData1'].astype(str)\n",
    "# Iterate over the columns in the DataFrame\n",
    "for col in df_2_grouped.columns:\n",
    "    # If the column name contains \"RestingECG_ExtraQuestions\"\n",
    "    if \"RestingECG_ExtraQuestions\" in col:\n",
    "        # Convert the column to string type\n",
    "        df_2_grouped[col] = df_2_grouped[col].astype(str)\n",
    "    elif \"RestingECG_Order\" in col:\n",
    "        df_2_grouped[col] = df_2_grouped[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_grouped.to_parquet(\n",
    "    \"/media/data1/ravram/DeepECG/ekg_waveforms_output/df_xml_2023_05_09_2004-to-june-2022_n_1572280_with_labelbox_no_duplicates.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot dataset distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_grouped = pd.read_parquet('/media/data1/ravram/DeepECG/ekg_waveforms_output/df_xml_2023_05_09_2004-to-june-2022_n_1572280_with_labelbox_no_duplicates.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert the 'RestingECG_TestDemographics_AcquisitionDate' column to datetime\n",
    "df_2_grouped['RestingECG_TestDemographics_AcquisitionDate'] = pd.to_datetime(df_2_grouped['RestingECG_TestDemographics_AcquisitionDate'])\n",
    "\n",
    "# Extract the year and count the number of entries per year\n",
    "entries_per_year = df_2_grouped['RestingECG_TestDemographics_AcquisitionDate'].dt.year.value_counts()\n",
    "\n",
    "# Sort the years\n",
    "entries_per_year = entries_per_year.sort_index()\n",
    "\n",
    "# Plot the number of entries per year\n",
    "entries_per_year.plot(kind='bar', figsize=(12,6))\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Entries')\n",
    "plt.title('Number of Entries per Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert the 'RestingECG_TestDemographics_AcquisitionDate' column to datetime\n",
    "df_2['RestingECG_TestDemographics_AcquisitionDate'] = pd.to_datetime(df_2['RestingECG_TestDemographics_AcquisitionDate'])\n",
    "\n",
    "# Filter the dataframe for entries since 2018\n",
    "df_2 = df_2[df_2['RestingECG_TestDemographics_AcquisitionDate'].dt.year >= 2018]\n",
    "\n",
    "# Create new columns for year and month\n",
    "df_2['Year'] = df_2['RestingECG_TestDemographics_AcquisitionDate'].dt.year\n",
    "df_2['Month'] = df_2['RestingECG_TestDemographics_AcquisitionDate'].dt.month\n",
    "\n",
    "# Group by year and month, and count the number of entries\n",
    "entries_per_month = df_2.groupby(['Year', 'Month']).size()\n",
    "\n",
    "# Plot the number of entries per month for each year\n",
    "entries_per_month.plot(kind='bar', figsize=(12,6))\n",
    "\n",
    "plt.xlabel('Year, Month')\n",
    "plt.ylabel('Number of Entries')\n",
    "plt.title('Number of Entries per Month (Since 2018)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_output['ecg_abnormal'] = np.where(df_output['Diagnosis'].str.contains('ECG anormal'), 1, np.where(df_output['Diagnosis'].str.contains('ECG normal'), 0, -1))\n",
    "# Remove ECG anormal and ECG normal from diagnosis\n",
    "# df_output['Diagnosis'] = df_output['Diagnosis'].str.replace('ECG anormal', '')\n",
    "# df_output['Original_Diagnosis'] = df_output['Original_Diagnosis'].str.replace('ECG normal', '')\n",
    "# df_output['Original_Diagnosis'] = df_output['Diagnosis'].str.replace('ECG anormal', '')\n",
    "# df_output['Diagnosis'] = df_output['Original_Diagnosis'].str.replace('ECG normal', '')\n",
    "# df_output.to_csv('data/20221002_ECG_mod_diagnosis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = (\n",
    "    df_output.groupby([\"patientid\", \"AcquisitionDate\", \"AcquisitionTime\"])\n",
    "    .first()\n",
    "    .reset_index()\n",
    ")\n",
    "display(df_stats(df_output))\n",
    "display(df_stats(df_m))\n",
    "## The ECGs can be grouped by patient id, date and time to have a 1 unique row per ECG - this means the filename to save the ECG also needs to have the date and time in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir = os.getcwd() + '/ekg_waveforms_output/'\n",
    "# ekg_batch_run(df['path'][0:1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Run CLI_xml2df by Alexis to generate NUMPY ARRAYS and SAVE dataset as PARQUET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.height', 1000)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"max_colwidth\", 200)\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"R_HOME\"] = \"/root/miniconda3/envs/R/lib/R\"\n",
    "\n",
    "import rpy2.robjects as objects\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "base = importr(\"base\")\n",
    "r_pROC = importr(\"pROC\")\n",
    "base._libPaths()[0]\n",
    "\n",
    "# Group by year and month, and count the number of entries\n",
    "entries_per_month = df_2.groupby(['Year', 'Month']).size()\n",
    "\n",
    "def df_stats(df):\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    print(\"\\n***** Shape: \", df.shape, \" *****\\n\")\n",
    "\n",
    "    columns_list = df.columns.values.tolist()\n",
    "    isnull_list = df.isnull().sum().values.tolist()\n",
    "    isunique_list = df.nunique().values.tolist()\n",
    "    dtypes_list = df.dtypes.tolist()\n",
    "\n",
    "    list_stat_val = list(zip(columns_list, isnull_list, isunique_list, dtypes_list))\n",
    "    df_stat_val = pd.DataFrame(\n",
    "        list_stat_val, columns=[\"Name\", \"Null\", \"Unique\", \"Dtypes\"]\n",
    "    )\n",
    "    print(tabulate(df_stat_val, headers=\"keys\", tablefmt=\"psql\"))\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/20230313_ECG_path.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CLI_xml2df as xml2df\n",
    "\n",
    "df_output = xml2df.tinyxml2df(\n",
    "    df[\"path\"], out_path=\"data/ekg_waveforms_output/\"\n",
    ").read2flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_output.to_csv('data/20230328_ECG_path_diagnosis_fixed_with_NPY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.to_parquet(\n",
    "    \"/media/data1/ravram/DeepECG/ekg_waveforms_output/df_xml_2023_03_30_n_1633856.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_array = np.load(df_output[\"npy_path\"][0])\n",
    "# Transpose the array to shape=[12, 2500]\n",
    "ecg_transposed = np.transpose(npy_array, (1, 0, 2))\n",
    "ecg_transposed = ecg_transposed.reshape(12, 2500)\n",
    "\n",
    "import ecg_plot\n",
    "\n",
    "ecg_plot.plot(ecg_transposed, sample_rate=250, title=\"ECG 12\")\n",
    "ecg_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot line of ecg_transposed[0] and ecg_transposed[1]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(ecg_transposed[0])\n",
    "plt.plot(ecg_transposed[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate ECGs for LABELBOX ANNOTATION - TOP 3600 DIAGNOSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.height', 1000)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"max_colwidth\", 200)\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "def normalize_string(s):\n",
    "    s = unidecode(s)\n",
    "    s = s.strip()\n",
    "    s = re.sub(r\"\\W+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def contains_eligible_diagnosis(normalized_diag, eligible_diagnoses):\n",
    "    # Initialize a variable to store the longest diagnosis and its length\n",
    "    longest_diagnosis = None\n",
    "    longest_length = 0\n",
    "\n",
    "    # Iterate over eligible_diagnoses\n",
    "    for diagnosis in eligible_diagnoses:\n",
    "        # Check if diagnosis is in normalized_diag\n",
    "        if diagnosis in normalized_diag:\n",
    "            # Check if the length of the current diagnosis is greater than the current longest_length\n",
    "            if len(diagnosis) > longest_length:\n",
    "                # Update the longest_diagnosis and longest_length\n",
    "                longest_diagnosis = diagnosis\n",
    "                longest_length = len(diagnosis)\n",
    "                \n",
    "    if (longest_diagnosis != None):\n",
    "        # Return the longest_diagnosis\n",
    "        return longest_diagnosis\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def filter_ecg_by_diagnosis(df_ecg, df_ecg_sampled):\n",
    "    df_ecg[\"Normalized_Diagnosis_MUSE\"] = df_ecg[\"diagnosis\"].apply(normalize_string)\n",
    "    df_ecg_sampled[\"Normalized_Diagnosis_LABELBOX\"] = df_ecg_sampled[\"Original_Diagnosis\"].apply(\n",
    "        normalize_string\n",
    "    )\n",
    "\n",
    "    eligible_diagnoses = set(df_ecg_sampled[\"Normalized_Diagnosis_LABELBOX\"])\n",
    "\n",
    "    df_ecg[\"Normalized_Diagnosis_LABELBOX\"] = df_ecg[\"Normalized_Diagnosis_MUSE\"].apply(\n",
    "        lambda x: contains_eligible_diagnosis(x, eligible_diagnoses)\n",
    "    )\n",
    "\n",
    "    return df_ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ecg = pd.read_parquet(\n",
    "    \"/media/data1/ravram/DeepECG/ekg_waveforms_output/df_xml_2023_03_30_n_1633856.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ecg = pd.read_parquet(\n",
    "    \"/media/data1/ravram/DeepECG/ekg_waveforms_output/df_xml_2023_03_30_n_1633856.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the folder path in the npy_path column\n",
    "#df_ecg['npy_path'] = df_ecg['npy_path'].replace(\n",
    "#    r'data/ekg_waveforms_output/ecg_npy/', \n",
    "#    '/media/data1/ravram/DeepECG/ekg_waveforms_output/ecg_npy/', \n",
    "#    regex=True\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Check if df_ecg['npy_path'] exists\n",
    "display(df_ecg.npy_path)#\n",
    "df_ecg[0:10000]['npy_path'].apply(lambda x: os.path.exists(x)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ecg_sampled = pd.read_csv(\"data/20221002_ECG_mod_diagnosis_sampled_3600.csv\")\n",
    "df_ecg_sampled = df_ecg_sampled.groupby(['Diagnosis']).first()\n",
    "display(df_ecg_sampled.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def save_ecg_plots(df_output_sampled, output_dir, diagonsis_column='diagnosis', figsize=(16, 9), dpi=300, lead_order=None):\n",
    "    if lead_order is None:\n",
    "        lead_order = [\n",
    "            \"I\",\n",
    "            \"II\",\n",
    "            \"III\",\n",
    "            \"aVR\",\n",
    "            \"aVL\",\n",
    "            \"aVF\",\n",
    "            \"V1\",\n",
    "            \"V2\",\n",
    "            \"V3\",\n",
    "            \"V4\",\n",
    "            \"V5\",\n",
    "            \"V6\",\n",
    "        ]\n",
    "\n",
    "    path_to_output = os.path.join(os.getcwd(), output_dir)\n",
    "    \n",
    "    if not os.path.exists(path_to_output):\n",
    "        os.mkdir(path_to_output)\n",
    "\n",
    "    for index, row in tqdm(df_output_sampled.iterrows()):\n",
    "        path = os.path.join(row[\"npy_path\"])\n",
    "        file = np.load(path)\n",
    "        file = np.reshape(file, (1, 2500, 12))\n",
    "\n",
    "        plt.rcParams[\"figure.figsize\"] = figsize\n",
    "        plt.ioff()\n",
    "        fig, axs = plt.subplots(len(lead_order))\n",
    "        \n",
    "        for i in range(12):\n",
    "            if i == 0:\n",
    "                axs[i].set_title(row[diagonsis_column])\n",
    "            axs[i].plot(file[0][:, i])\n",
    "            axs[i].set(ylabel=str(lead_order[i]))\n",
    "\n",
    "        AcquisitionDateTime = row[\"RestingECG_TestDemographics_AcquisitionDate\"] + \"_\" + row[\"RestingECG_TestDemographics_AcquisitionTime\"].replace(\":\", \"-\")\n",
    "        filename = f\"{row['RestingECG_PatientDemographics_PatientID']}_{AcquisitionDateTime}.png\"\n",
    "        \n",
    "        file_output = os.path.join(path_to_output, filename)\n",
    "        print(file_output)\n",
    "        \n",
    "        plt.savefig(file_output, dpi=dpi, bbox_inches=\"tight\")\n",
    "        plt.close(fig)df_ecg_sampled = pd.read_csv(\"data/20221002_ECG_mod_diagnosis_sampled_3600.csv\")\n",
    "df_ecg_sampled = df_ecg_sampled.groupby(['Diagnosis']).first()\n",
    "display(df_ecg_sampled.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_ecg_plots(df_f[6511:6513], output_dir=\"sanity_check/\")import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def save_ecg_plots(df_output_sampled, output_dir, diagonsis_column='diagnosis', figsize=(16, 9), dpi=300, lead_order=None):\n",
    "    if lead_order is None:\n",
    "        lead_order = [\n",
    "            \"I\",\n",
    "            \"II\",\n",
    "            \"III\",\n",
    "            \"aVR\",\n",
    "            \"aVL\",\n",
    "            \"aVF\",\n",
    "            \"V1\",\n",
    "            \"V2\",\n",
    "            \"V3\",\n",
    "            \"V4\",\n",
    "            \"V5\",\n",
    "            \"V6\",\n",
    "        ]\n",
    "\n",
    "    path_to_output = os.path.join(os.getcwd(), output_dir)\n",
    "    \n",
    "    if not os.path.exists(path_to_output):\n",
    "        os.mkdir(path_to_output)\n",
    "\n",
    "    for index, row in tqdm(df_output_sampled.iterrows()):\n",
    "        path = os.path.join(row[\"npy_path\"])\n",
    "        file = np.load(path)\n",
    "        file = np.reshape(file, (1, 2500, 12))\n",
    "\n",
    "        plt.rcParams[\"figure.figsize\"] = figsize\n",
    "        plt.ioff()\n",
    "        fig, axs = plt.subplots(len(lead_order))\n",
    "        \n",
    "        for i in range(12):\n",
    "            if i == 0:\n",
    "                axs[i].set_title(row[diagonsis_column])\n",
    "            axs[i].plot(file[0][:, i])\n",
    "            axs[i].set(ylabel=str(lead_order[i]))\n",
    "\n",
    "        AcquisitionDateTime = row[\"RestingECG_TestDemographics_AcquisitionDate\"] + \"_\" + row[\"RestingECG_TestDemographics_AcquisitionTime\"].replace(\":\", \"-\")\n",
    "        filename = f\"{row['RestingECG_PatientDemographics_PatientID']}_{AcquisitionDateTime}.png\"\n",
    "        \n",
    "        file_output = os.path.join(path_to_output, filename)\n",
    "        print(file_output)\n",
    "        \n",
    "        plt.savefig(file_output, dpi=dpi, bbox_inches=\"tight\")\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_ecg_plots(df_f[6511:6513], output_dir=\"sanity_check/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = filter_ecg_by_diagnosis(df_ecg, df_ecg_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply this if the \"Contains_Eligible_Diagnosis\" is not FALSE; if it is false, return 0\n",
    "df_f['percentage_labelbox_string_present_in_original_string'] = df_f.apply(lambda x: len(x['Normalized_Diagnosis_LABELBOX'])/len(x['diagnosis']) if x['Normalized_Diagnosis_LABELBOX'] != False else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_f.percentage_labelbox_string_present_in_original_string.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f['Normalized_Diagnosis_LABELBOX'] = df_f['Normalized_Diagnosis_LABELBOX'].astype(str)\n",
    "df_f = df_f.drop(['RestingECG_PatientDemographics_PatientFirstName'], axis=1)\n",
    "df_f = df_f.drop(['RestingECG_PatientDemographics_PatientLastName'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f['Normalized_Diagnosis_LABELBOX'] = df_f['Normalized_Diagnosis_LABELBOX'].astype(str)\n",
    "df_f = df_f.drop(['RestingECG_PatientDemographics_PatientFirstName'], axis=1)\n",
    "df_f = df_f.drop(['RestingECG_PatientDemographics_PatientLastName'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f.to_parquet(\n",
    "    \"/media/data1/ravram/DeepECG/ekg_waveforms_output/df_xml_2023_03_30_n_1633856_with_labelbox.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1) Voir quelles données labelbox sont discordantes et me les envoyer pour annotation (et enlever ces ECG de la base de données)\n",
    "### 2) Faire propagation des données labelbox concordantes sur df_ecg (db. parquet)\n",
    "### 3) Dictionnaire pour df_ecg['Contains_Eligible_Diagnosis']==False\n",
    "### 4) Standardiser le dataloader"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
