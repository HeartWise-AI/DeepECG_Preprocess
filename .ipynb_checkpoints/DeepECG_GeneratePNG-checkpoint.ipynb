{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.height', 1000)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"max_colwidth\", 200)\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"R_HOME\"] = \"/root/miniconda3/envs/R/lib/R\"\n",
    "\n",
    "import rpy2.robjects as objects\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "base = importr(\"base\")\n",
    "r_pROC = importr(\"pROC\")\n",
    "base._libPaths()[0]\n",
    "\n",
    "\n",
    "def df_stats(df):\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    print(\"\\n***** Shape: \", df.shape, \" *****\\n\")\n",
    "\n",
    "    columns_list = df.columns.values.tolist()\n",
    "    isnull_list = df.isnull().sum().values.tolist()\n",
    "    isunique_list = df.nunique().values.tolist()\n",
    "    dtypes_list = df.dtypes.tolist()\n",
    "\n",
    "    list_stat_val = list(zip(columns_list, isnull_list, isunique_list, dtypes_list))\n",
    "    df_stat_val = pd.DataFrame(\n",
    "        list_stat_val, columns=[\"Name\", \"Null\", \"Unique\", \"Dtypes\"]\n",
    "    )\n",
    "    print(tabulate(df_stat_val, headers=\"keys\", tablefmt=\"psql\"))\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_title_line(title_text, split_on=\"(\", max_words=25):  # , max_words=None):\n",
    "    \"\"\"\n",
    "    A function that splits any string based on specific character\n",
    "    (returning it with the string), with maximum number of words on it\n",
    "    \"\"\"\n",
    "    split_at = title_text.find(split_on)\n",
    "    ti = title_text\n",
    "    if split_at > 1:\n",
    "        ti = ti.split(split_on)\n",
    "        for i, tx in enumerate(ti[1:]):\n",
    "            ti[i + 1] = split_on + tx\n",
    "    if type(ti) == str:\n",
    "        ti = [ti]\n",
    "    for j, td in enumerate(ti):\n",
    "        if td.find(split_on) > 0:\n",
    "            pass\n",
    "        else:\n",
    "            tw = td.split()\n",
    "            t2 = []\n",
    "            for i in range(0, len(tw), max_words):\n",
    "                t2.append(\" \".join(tw[i : max_words + i]))\n",
    "            ti[j] = t2\n",
    "    ti = [item for sublist in ti for item in sublist]\n",
    "    ret_tex = []\n",
    "    for j in range(len(ti)):\n",
    "        for i in range(0, len(ti) - 1, 2):\n",
    "            if len(ti[i].split()) + len(ti[i + 1].split()) <= max_words:\n",
    "                mrg = \" \".join([ti[i], ti[i + 1]])\n",
    "                ti = [mrg] + ti[2:]\n",
    "                break\n",
    "    try:\n",
    "        if len(ti[-2].split()) + len(ti[-1].split()) <= max_words:\n",
    "            mrg = \" \".join([ti[-2], ti[-1]])\n",
    "            ti = ti[:-2] + [mrg]\n",
    "        return \"\\n\".join(ti)\n",
    "    except:\n",
    "        return ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output = pd.read_csv(\"data/20221002_ECG_mod_diagnosis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Restrict df_output to 1000 most frequent diagnoses\n",
    "df_output_m = df_output.groupby(\"Diagnosis\").filter(lambda x: len(x) > 10)\n",
    "display(len(df_output_m.Diagnosis.value_counts()))\n",
    "## Randomly sample 2 of df_output['Diagnosis]\n",
    "df_output_sampled = (\n",
    "    df_output_m.groupby(\"Diagnosis\")\n",
    "    .apply(lambda x: x.sample(2, random_state=1))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "display(df_output_sampled.Diagnosis.value_counts())\n",
    "df_output_sampled.to_csv(\"data/20221002_ECG_mod_diagnosis_sampled_3600.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_dir = \"/ekg_JPEG/\"\n",
    "path_to_output = os.getcwd() + output_dir\n",
    "\n",
    "if not os.path.exists(path_to_output):\n",
    "    os.mkdir(path_to_output)\n",
    "\n",
    "for index, row in tqdm(df_output_sampled.iterrows()):\n",
    "    path = os.path.join(row[\"ecg_output_path\"])\n",
    "    file = np.load(path)\n",
    "    file = np.reshape(file, (1, 2500, 12))\n",
    "\n",
    "    # To reconstruct the 12 lead ecg from the array\n",
    "    lead_order = [\n",
    "        \"I\",\n",
    "        \"II\",\n",
    "        \"III\",\n",
    "        \"aVR\",\n",
    "        \"aVL\",\n",
    "        \"aVF\",\n",
    "        \"V1\",\n",
    "        \"V2\",\n",
    "        \"V3\",\n",
    "        \"V4\",\n",
    "        \"V5\",\n",
    "        \"V6\",\n",
    "    ]\n",
    "    plt.rcParams[\"figure.figsize\"] = [16, 9]\n",
    "    ## Do not display plot in notebook\n",
    "    plt.ioff()\n",
    "    fig, axs = plt.subplots(len(lead_order))\n",
    "    for i in range(12):\n",
    "        if i == 0:\n",
    "            axs[i].set_title(split_title_line(row[\"Diagnosis\"]))\n",
    "        axs[i].plot(file[0][:, i])\n",
    "        axs[i].set(ylabel=str(lead_order[i]))\n",
    "\n",
    "    ## Save plt to JPEG\n",
    "    AcquisitionDateTime = (\n",
    "        row[\"AcquisitionDate\"] + \"_\" + row[\"AcquisitionTime\"].replace(\":\", \"-\")\n",
    "    )\n",
    "\n",
    "    filename = f\"{row['patientid']}_{AcquisitionDateTime}.png\"\n",
    "\n",
    "    file_output = path_to_output + filename\n",
    "    # print(path_to_output)\n",
    "\n",
    "    plt.savefig(file_output, dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre processing for NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npyfilespath = os.getcwd() + \"/ekg_waveforms_output/\"\n",
    "os.chdir(npyfilespath)\n",
    "npfiles = glob.glob(\"*.npy\")\n",
    "npfiles.sort()\n",
    "all_arrays_train = []\n",
    "# all_arrays_eval = []\n",
    "\n",
    "# If trying to test model quickly use smaller total dataset or change dataloader to load npy file batch by batch\n",
    "# Not rewriting stacked array so below is commented out\n",
    "\n",
    "for i, npfile in enumerate(npfiles):\n",
    "    x = 0\n",
    "    i = 0\n",
    "    try:\n",
    "        path = os.path.join(npyfilespath + npfile)\n",
    "        file = np.load(path)\n",
    "\n",
    "        file = np.reshape(file, (1, 2500, 12))\n",
    "        all_arrays_train.append(file)\n",
    "        x += 1\n",
    "        i += 1\n",
    "    except:\n",
    "        continue\n",
    "    if i % 1 == 100:\n",
    "        print(\"{i} EKGs have been written to array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_arrays_train = np.array(all_arrays_train)\n",
    "reshaped = np.reshape(all_arrays_train, (all_arrays_train.shape[0], 2500, 12))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
